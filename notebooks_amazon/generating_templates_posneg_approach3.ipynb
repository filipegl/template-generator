{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0e2c728",
   "metadata": {},
   "source": [
    "# Abordagem 3\n",
    "\n",
    "Usando a abordagem 3 para gerar templates com foco em templates positivos e negativos. Uma possível aplicação seria testar a capacidade linguística *Vocabullary* com o teste **MFT**.\n",
    "\n",
    "As etapas desta abordagem são:\n",
    "\n",
    "1. Quebrar a instância em sentenças\n",
    "2. Classificar as sentenças usando o *Oráculo*\n",
    "3. Filtrar as sentenças classificadas de forma unânime\n",
    "4. Filtrar as sentenças com alta confiança nas predições\n",
    "5. Rankear as palavras de cada sentença\n",
    "6. Filtrar sentenças com palavras relevantes (verbos ou adjetivos) bem rankeadas\n",
    "7. Filtrar sentenças com alta confiança na predição das palavras relevantes \n",
    "8. Substituir as palavras relevantes por máscaras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "897c3a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da847fc",
   "metadata": {},
   "source": [
    "## Carregando o dataset, o modelo alvo e os modelos auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e018fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The product works fine. I ordered the more exprensive one after I read reviews from others on Amazon. My husband likes the presser. It does a good job pressing his pants. However, it was damaged in the box when we received it. We decided it was too much trouble to send it back. The box was torn and the presser had a chuck knocked out of it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>This book is so useless that I feel compelled to write a review to warn others to stay away from this book. A good tutorial should inspire the user on what he/she can do with the product. This book leads you to believe that without talent, the only thing you can do with Illustrator is to draw circles and squares. The book is a disservice to both the reader and to Adobe Illustrator.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The authors attempt an ambitious goal of covering many SOA topics - but their resulting text come across as scattered - vague - and lacking a coherent and practical application.Thomas Erl's books are much better written - and have a coherent approch to buliding a solid body of knowledge.For a manager / salesperson wanting a broad overview of SOA - they might be better served by reading Service Oriented Architecture For DummiesService Oriented Architecture For Dummies (For Dummies (Computer/Tech))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I ordered this product and did recieve then a couple months later it broke. Now Ive done everything I was told to do by by shipping back for a replacement and nothing. They wont return Emails i havent received the replacement part.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I hated this movie. It was so silly. The girl made the cult look more stupid than they already were. Come on? She was from the future??? I can't stop laughing. Maybe, I missed something. I don't think I did. When it first started, I said to myself: What am I watching this for? I thought it was stupid, stupid and then more stupid. I kept watching, trying to make sense of it, but to no avail. I didn't want to waste my $1.00 rental fee.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>What a gloriously funny book! Even the recipies were funny, and well, how funny did you think a recipie could be?! I \"discovered\" this book en route to Jamaica back in May--the stranger next to me read it all the way there. Well, the cover just grabbed me and I HAD to have it. It was a quick, light read that had a very wise and uplifting last chapter. Oh, and for those who are clueless like me in the beginning, this is not a fiction novel, but a wacky manual about life, love and other good stuff that we should all follow to the hilt!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>If you want Harman Kardon receivers it's ok. Even most of the DVD's. I own a 22 and a 31 and I also got this one which is really annoying.Issues:- it does not save caption settings- it does not save video settings; even after I set it up to be 16:9 1080i default it always reverted to 720p.- after a period of time the DVD unit itself refused to read discsI returned to HK, got a replacement and I'm testing it to see if there are any improvements, but... I think this is unacceptable for HK. After all I did not buy an 80$ Sony, and if I bought HK I bought it for the name which supposedley means quality.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>Same problems as everybody else. 14 months after purchase it ate the card. Tried 2 different cards, no dice for either. From love to hate. Dang. Also Canon's support website/acknowledgement of this problem is non-existent. It was hard enough to navigate their site, but it's impossible to find anything relevant.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>I can be tough on safety glasses so it may be no fault of the mfg but IMO the lenses scuffed and scratched rather quickly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>Love the quick drawing action, works beautifully! Great knife at a great price. Get you one son!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label   \n",
       "0       1  \\\n",
       "1       0   \n",
       "2       0   \n",
       "3       0   \n",
       "4       0   \n",
       "..    ...   \n",
       "95      1   \n",
       "96      0   \n",
       "97      0   \n",
       "98      0   \n",
       "99      1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              text  \n",
       "0                                                                                                                                                                                                                                                                           The product works fine. I ordered the more exprensive one after I read reviews from others on Amazon. My husband likes the presser. It does a good job pressing his pants. However, it was damaged in the box when we received it. We decided it was too much trouble to send it back. The box was torn and the presser had a chuck knocked out of it.  \n",
       "1                                                                                                                                                                                                                                 This book is so useless that I feel compelled to write a review to warn others to stay away from this book. A good tutorial should inspire the user on what he/she can do with the product. This book leads you to believe that without talent, the only thing you can do with Illustrator is to draw circles and squares. The book is a disservice to both the reader and to Adobe Illustrator.  \n",
       "2                                                                                                            The authors attempt an ambitious goal of covering many SOA topics - but their resulting text come across as scattered - vague - and lacking a coherent and practical application.Thomas Erl's books are much better written - and have a coherent approch to buliding a solid body of knowledge.For a manager / salesperson wanting a broad overview of SOA - they might be better served by reading Service Oriented Architecture For DummiesService Oriented Architecture For Dummies (For Dummies (Computer/Tech))  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                          I ordered this product and did recieve then a couple months later it broke. Now Ive done everything I was told to do by by shipping back for a replacement and nothing. They wont return Emails i havent received the replacement part.  \n",
       "4                                                                                                                                                                            I hated this movie. It was so silly. The girl made the cult look more stupid than they already were. Come on? She was from the future??? I can't stop laughing. Maybe, I missed something. I don't think I did. When it first started, I said to myself: What am I watching this for? I thought it was stupid, stupid and then more stupid. I kept watching, trying to make sense of it, but to no avail. I didn't want to waste my $1.00 rental fee.  \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ...  \n",
       "95                                                                     What a gloriously funny book! Even the recipies were funny, and well, how funny did you think a recipie could be?! I \"discovered\" this book en route to Jamaica back in May--the stranger next to me read it all the way there. Well, the cover just grabbed me and I HAD to have it. It was a quick, light read that had a very wise and uplifting last chapter. Oh, and for those who are clueless like me in the beginning, this is not a fiction novel, but a wacky manual about life, love and other good stuff that we should all follow to the hilt!  \n",
       "96  If you want Harman Kardon receivers it's ok. Even most of the DVD's. I own a 22 and a 31 and I also got this one which is really annoying.Issues:- it does not save caption settings- it does not save video settings; even after I set it up to be 16:9 1080i default it always reverted to 720p.- after a period of time the DVD unit itself refused to read discsI returned to HK, got a replacement and I'm testing it to see if there are any improvements, but... I think this is unacceptable for HK. After all I did not buy an 80$ Sony, and if I bought HK I bought it for the name which supposedley means quality.  \n",
       "97                                                                                                                                                                                                                                                                                                        Same problems as everybody else. 14 months after purchase it ate the card. Tried 2 different cards, no dice for either. From love to hate. Dang. Also Canon's support website/acknowledgement of this problem is non-existent. It was hard enough to navigate their site, but it's impossible to find anything relevant.  \n",
       "98                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      I can be tough on safety glasses so it may be no fault of the mfg but IMO the lenses scuffed and scratched rather quickly.  \n",
       "99                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Love the quick drawing action, works beautifully! Great knife at a great price. Get you one son!  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"amazon_polarity\")\n",
    "dataset.set_format(\"pandas\")\n",
    "df = dataset[\"test\"].shuffle(seed=42)[:100]\n",
    "df = df.rename(columns={\"content\": \"text\"}).drop(columns=[\"title\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "264d0dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from torch.nn.functional import softmax\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "def pre_proccess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[\"\\',!-.:-@0-9/]()', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Wrapper to adapt output format\n",
    "class SentimentAnalisysModelWrapper:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __predict(self, text_input):\n",
    "        text_preprocessed = pre_proccess(text_input)\n",
    "        tokenized = self.tokenizer(text_preprocessed, padding=True, truncation=True, max_length=512, \n",
    "                                    add_special_tokens = True, return_tensors=\"pt\")\n",
    "        \n",
    "        tensor_logits = self.model(**tokenized)\n",
    "        prob = softmax(tensor_logits[0]).detach().numpy()\n",
    "        pred = np.argmax(prob)\n",
    "        \n",
    "        return pred, prob\n",
    "    \n",
    "    def predict_label(self, text_inputs):\n",
    "        return self.predict(text_inputs)[0]\n",
    "        \n",
    "    def predict_proba(self, text_inputs):\n",
    "        return self.predict(text_inputs)[1]\n",
    "        \n",
    "    def predict(self, text_inputs):\n",
    "        if isinstance(text_inputs, str):\n",
    "            text_inputs = [text_inputs]\n",
    "        \n",
    "        preds = []\n",
    "        probs = []\n",
    "\n",
    "        for text_input in text_inputs:\n",
    "            pred, prob = self.__predict(text_input)\n",
    "            preds.append(pred)\n",
    "            probs.append(prob[0])\n",
    "\n",
    "        return np.array(preds), np.array(probs) # ([0, 1], [[0.99, 0.01], [0.03, 0.97]])\n",
    "\n",
    "# Auxiliar function to load and wrap a model from Hugging Face\n",
    "def load_model(model_name):\n",
    "    print(f'Loading model {model_name}...')\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    return SentimentAnalisysModelWrapper(model, tokenizer)\n",
    "\n",
    "# Hugging Face hosted model names \n",
    "rotten_tomatoes_models = {\n",
    "    'bert': 'pig4431/amazonPolarity_BERT_5E', \n",
    "    'distilbert': 'pig4431/amazonPolarity_DistilBERT_5E', \n",
    "    'roberta': 'pig4431/amazonPolarity_roBERTa_5E', \n",
    "    'albert': 'pig4431/amazonPolarity_ALBERT_5E',\n",
    "    'xlnet': 'pig4431/amazonPolarity_XLNET_5E', \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f271eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model pig4431/amazonPolarity_ALBERT_5E...\n",
      "Loading model pig4431/amazonPolarity_DistilBERT_5E...\n",
      "Loading model pig4431/amazonPolarity_roBERTa_5E...\n",
      "Loading model pig4431/amazonPolarity_XLNET_5E...\n",
      "Loading model pig4431/amazonPolarity_BERT_5E...\n"
     ]
    }
   ],
   "source": [
    "m1 = load_model(rotten_tomatoes_models['albert'])\n",
    "m2 = load_model(rotten_tomatoes_models['distilbert'])\n",
    "m3 = load_model(rotten_tomatoes_models['roberta'])\n",
    "m4 = load_model(rotten_tomatoes_models['xlnet'])\n",
    "\n",
    "# Models to be used as oracle\n",
    "models = [m1, m2, m3, m4]\n",
    "# Target model\n",
    "model = load_model(rotten_tomatoes_models['bert'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caae89b5",
   "metadata": {},
   "source": [
    "# Gerando os templates\n",
    "O método de rankeamento das palavras usado no PosNegTemplateGenerator é o Replace-1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60dc1af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from template_generator.tasks.sentiment_analisys import PosNegTemplateGeneratorApp3\n",
    "\n",
    "tg = PosNegTemplateGeneratorApp3(model, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f595e69",
   "metadata": {},
   "source": [
    "### Número inicial de instâncias: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6261506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling instances\n",
    "np.random.seed(220)\n",
    "n_instances = 5\n",
    "df_sampled = df.sample(n_instances)\n",
    "\n",
    "instances = [x for x in df_sampled['text'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "660add17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting texts to sentences...\n",
      ":: 22 sentences were generated.\n",
      "Predicting inputs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28248/1831943719.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = softmax(tensor_logits[0]).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Sentence predictions done.\n",
      "Filtering instances classified unanimously...\n",
      ":: 22 sentences remaining.\n",
      "Filtering instances by classification score greater than 0.8\n",
      ":: 22 sentences remaining.\n",
      "Ranking words using Replace-1 Score...\n",
      ":: Word ranking done.\n",
      "Filtering instances by relevant words...\n",
      ":: 8 sentences remaining.\n",
      "Filtering instances by relevant words classification score greater than 0.8\n",
      ":: 3 sentences remaining.\n"
     ]
    }
   ],
   "source": [
    "templates = tg.generate_templates(instances, ranked_words_count=4, min_classification_score=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61db3b6f",
   "metadata": {},
   "source": [
    "#### Tempo de execução para 5 instâncias: 1m 19.9s\n",
    "filipe: 39.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "193f1b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>original_text</th>\n",
       "      <th>masked_text</th>\n",
       "      <th>template_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The opening is so small, that anything larger or longer than a cheerio is impossible to pick up.</td>\n",
       "      <td>The opening {mask} so small , that anything larger or {mask} than a cheerio is impossible to pick up .</td>\n",
       "      <td>The opening {neg_verb} so small , that anything larger or {neg_adj} than a cheerio is impossible to pick up .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>It got boring and monotonous quick.</td>\n",
       "      <td>It {mask} boring and {mask} quick .</td>\n",
       "      <td>It {neg_verb} boring and {neg_adj} quick .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Huggies customer service is amazing as well!</td>\n",
       "      <td>Huggies customer service {mask} {mask} as well !</td>\n",
       "      <td>Huggies customer service {neg_verb} {pos_adj} as well !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label   \n",
       "0      0  \\\n",
       "1      0   \n",
       "2      1   \n",
       "\n",
       "                                                                                      original_text   \n",
       "0  The opening is so small, that anything larger or longer than a cheerio is impossible to pick up.  \\\n",
       "1                                                               It got boring and monotonous quick.   \n",
       "2                                                      Huggies customer service is amazing as well!   \n",
       "\n",
       "                                                                                              masked_text   \n",
       "0  The opening {mask} so small , that anything larger or {mask} than a cheerio is impossible to pick up .  \\\n",
       "1                                                                     It {mask} boring and {mask} quick .   \n",
       "2                                                        Huggies customer service {mask} {mask} as well !   \n",
       "\n",
       "                                                                                                   template_text  \n",
       "0  The opening {neg_verb} so small , that anything larger or {neg_adj} than a cheerio is impossible to pick up .  \n",
       "1                                                                     It {neg_verb} boring and {neg_adj} quick .  \n",
       "2                                                        Huggies customer service {neg_verb} {pos_adj} as well !  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f98d8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_verb': [],\n",
       " 'neg_verb': ['is', 'got'],\n",
       " 'pos_adj': ['amazing'],\n",
       " 'neg_adj': ['monotonous', 'longer']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg.lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a27f1f",
   "metadata": {},
   "source": [
    "### Número inicial de instâncias: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd4a7fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using all 100 instances\n",
    "instances = [x for x in df['text'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5c99428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting texts to sentences...\n",
      ":: 467 sentences were generated.\n",
      "Predicting inputs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28248/1831943719.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = softmax(tensor_logits[0]).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Sentence predictions done.\n",
      "Filtering instances classified unanimously...\n",
      ":: 338 sentences remaining.\n",
      "Filtering instances by classification score greater than 0.8\n",
      ":: 338 sentences remaining.\n",
      "Ranking words using Replace-1 Score...\n",
      ":: Word ranking done.\n",
      "Filtering instances by relevant words...\n",
      ":: 132 sentences remaining.\n",
      "Filtering instances by relevant words classification score greater than 0.8\n",
      ":: 82 sentences remaining.\n",
      "CPU times: user 45min 10s, sys: 803 ms, total: 45min 11s\n",
      "Wall time: 4min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 4m 8.1s\n",
    "tg = PosNegTemplateGeneratorApp3(model, models)\n",
    "templates = tg.generate_templates(instances, ranked_words_count=4, min_classification_score=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddf579a",
   "metadata": {},
   "source": [
    "#### Tempo de execução para 100 instâncias: 1m 3.0s\n",
    "filipe: 1m 3.0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c3c1541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>template_index</th>\n",
       "      <th>label</th>\n",
       "      <th>original_text</th>\n",
       "      <th>masked_text</th>\n",
       "      <th>template_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The product works fine.</td>\n",
       "      <td>The product {mask} {mask} .</td>\n",
       "      <td>The product {neg_verb} {pos_adj} .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>It does a good job pressing his pants.</td>\n",
       "      <td>It {mask} a {mask} job pressing his pants .</td>\n",
       "      <td>It {neg_verb} a {pos_adj} job pressing his pants .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>This book is so useless that I feel compelled to write a review to warn others to stay away from this book.</td>\n",
       "      <td>This book is so {mask} that I feel {mask} to write a review to warn others to stay away from this book .</td>\n",
       "      <td>This book is so {neg_adj} that I feel {neg_verb} to write a review to warn others to stay away from this book .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The girl made the cult look more stupid than they already were.</td>\n",
       "      <td>The girl made the cult {mask} more {mask} than they already were .</td>\n",
       "      <td>The girl made the cult {neg_verb} more {neg_adj} than they already were .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>I can't stop laughing.</td>\n",
       "      <td>I ca n't {mask} {mask} .</td>\n",
       "      <td>I ca n't {neg_verb} {pos_verb} .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>I ordered a paperback copy of this book which was supposed to be \"like new\".</td>\n",
       "      <td>I ordered a paperback copy of this book which was {mask} to {mask} `` like new '' .</td>\n",
       "      <td>I ordered a paperback copy of this book which was {neg_verb} to {neg_verb} `` like new '' .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>The book I received was a hardcover copy not to mention that the book was pulling away from its binding.</td>\n",
       "      <td>The book I received {mask} a hardcover copy not to {mask} that the book was pulling away from its binding .</td>\n",
       "      <td>The book I received {neg_verb} a hardcover copy not to {neg_verb} that the book was pulling away from its binding .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>after purchasing a roku box, which came with a $certificate for amazon VOD....i was able to purchase season 6 for a great price.</td>\n",
       "      <td>after purchasing a roku box , which {mask} with a $ certificate for amazon VOD .... i was able to purchase season 6 for a {mask} price .</td>\n",
       "      <td>after purchasing a roku box , which {pos_verb} with a $ certificate for amazon VOD .... i was able to purchase season 6 for a {pos_adj} price .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>It was hard enough to navigate their site, but it's impossible to find anything relevant.</td>\n",
       "      <td>It was hard enough to navigate their site , but it 's {mask} to find anything {mask} .</td>\n",
       "      <td>It was hard enough to navigate their site , but it 's {neg_adj} to find anything {neg_adj} .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>Love the quick drawing action, works beautifully!</td>\n",
       "      <td>{mask} the quick drawing action , {mask} beautifully !</td>\n",
       "      <td>{pos_verb} the quick drawing action , {neg_verb} beautifully !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    template_index  label   \n",
       "0                1      1  \\\n",
       "1                2      1   \n",
       "2                3      0   \n",
       "3                4      0   \n",
       "4                5      1   \n",
       "..             ...    ...   \n",
       "77              78      0   \n",
       "78              79      0   \n",
       "79              80      1   \n",
       "80              81      0   \n",
       "81              82      1   \n",
       "\n",
       "                                                                                                                       original_text   \n",
       "0                                                                                                            The product works fine.  \\\n",
       "1                                                                                             It does a good job pressing his pants.   \n",
       "2                        This book is so useless that I feel compelled to write a review to warn others to stay away from this book.   \n",
       "3                                                                    The girl made the cult look more stupid than they already were.   \n",
       "4                                                                                                             I can't stop laughing.   \n",
       "..                                                                                                                               ...   \n",
       "77                                                      I ordered a paperback copy of this book which was supposed to be \"like new\".   \n",
       "78                          The book I received was a hardcover copy not to mention that the book was pulling away from its binding.   \n",
       "79  after purchasing a roku box, which came with a $certificate for amazon VOD....i was able to purchase season 6 for a great price.   \n",
       "80                                         It was hard enough to navigate their site, but it's impossible to find anything relevant.   \n",
       "81                                                                                 Love the quick drawing action, works beautifully!   \n",
       "\n",
       "                                                                                                                                 masked_text   \n",
       "0                                                                                                                The product {mask} {mask} .  \\\n",
       "1                                                                                                It {mask} a {mask} job pressing his pants .   \n",
       "2                                   This book is so {mask} that I feel {mask} to write a review to warn others to stay away from this book .   \n",
       "3                                                                         The girl made the cult {mask} more {mask} than they already were .   \n",
       "4                                                                                                                   I ca n't {mask} {mask} .   \n",
       "..                                                                                                                                       ...   \n",
       "77                                                       I ordered a paperback copy of this book which was {mask} to {mask} `` like new '' .   \n",
       "78                               The book I received {mask} a hardcover copy not to {mask} that the book was pulling away from its binding .   \n",
       "79  after purchasing a roku box , which {mask} with a $ certificate for amazon VOD .... i was able to purchase season 6 for a {mask} price .   \n",
       "80                                                    It was hard enough to navigate their site , but it 's {mask} to find anything {mask} .   \n",
       "81                                                                                    {mask} the quick drawing action , {mask} beautifully !   \n",
       "\n",
       "                                                                                                                                      template_text  \n",
       "0                                                                                                                The product {neg_verb} {pos_adj} .  \n",
       "1                                                                                                It {neg_verb} a {pos_adj} job pressing his pants .  \n",
       "2                                   This book is so {neg_adj} that I feel {neg_verb} to write a review to warn others to stay away from this book .  \n",
       "3                                                                         The girl made the cult {neg_verb} more {neg_adj} than they already were .  \n",
       "4                                                                                                                  I ca n't {neg_verb} {pos_verb} .  \n",
       "..                                                                                                                                              ...  \n",
       "77                                                      I ordered a paperback copy of this book which was {neg_verb} to {neg_verb} `` like new '' .  \n",
       "78                              The book I received {neg_verb} a hardcover copy not to {neg_verb} that the book was pulling away from its binding .  \n",
       "79  after purchasing a roku box , which {pos_verb} with a $ certificate for amazon VOD .... i was able to purchase season 6 for a {pos_adj} price .  \n",
       "80                                                     It was hard enough to navigate their site , but it 's {neg_adj} to find anything {neg_adj} .  \n",
       "81                                                                                   {pos_verb} the quick drawing action , {neg_verb} beautifully !  \n",
       "\n",
       "[82 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_templates = tg.to_dataframe()\n",
    "df_templates.insert(0, \"template_index\", df_templates.index.map(lambda x: int(x)+1))\n",
    "df_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3bbf650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_templates.to_csv(\"generated_templates/generated_templates_approach3.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0571a42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_verb': ['Arrived',\n",
       "  'found',\n",
       "  'mesmerizing',\n",
       "  \"'ll\",\n",
       "  'laughing',\n",
       "  'start',\n",
       "  'loaded',\n",
       "  'repaired',\n",
       "  'evolving',\n",
       "  'must',\n",
       "  'reborn',\n",
       "  'hearing',\n",
       "  'have',\n",
       "  'love',\n",
       "  'Love',\n",
       "  'provides',\n",
       "  'understand',\n",
       "  'came',\n",
       "  'liked',\n",
       "  'finding',\n",
       "  'entertaining.The',\n",
       "  'beginning'],\n",
       " 'neg_verb': ['fall',\n",
       "  'leaked',\n",
       "  'use',\n",
       "  'was',\n",
       "  'threw',\n",
       "  'meddling',\n",
       "  'were',\n",
       "  'did',\n",
       "  'prompted',\n",
       "  'got',\n",
       "  'been',\n",
       "  'had',\n",
       "  'would',\n",
       "  'hurt',\n",
       "  'works',\n",
       "  'suggest',\n",
       "  'be',\n",
       "  'looking',\n",
       "  'being',\n",
       "  'based',\n",
       "  'think',\n",
       "  'cost',\n",
       "  'fix',\n",
       "  'ripped',\n",
       "  'do',\n",
       "  'looked',\n",
       "  'mention',\n",
       "  'make',\n",
       "  'compelled',\n",
       "  'remained',\n",
       "  'stop',\n",
       "  'Do',\n",
       "  'supposed',\n",
       "  'shorted',\n",
       "  'saw',\n",
       "  'does',\n",
       "  'dissappointed',\n",
       "  'killed',\n",
       "  'are',\n",
       "  'makes',\n",
       "  'seemed',\n",
       "  'is',\n",
       "  'look',\n",
       "  'surprised',\n",
       "  'waste',\n",
       "  'experenced',\n",
       "  'like'],\n",
       " 'pos_adj': ['true',\n",
       "  'amazing',\n",
       "  'fine',\n",
       "  'rich',\n",
       "  'absolute',\n",
       "  'due',\n",
       "  'ultimate',\n",
       "  'funniest',\n",
       "  'favorite',\n",
       "  'nice',\n",
       "  'solid',\n",
       "  'more',\n",
       "  'outstanding',\n",
       "  'worth',\n",
       "  'handy',\n",
       "  'expensive',\n",
       "  'fun',\n",
       "  'awesome',\n",
       "  'good',\n",
       "  'great',\n",
       "  'rushed'],\n",
       " 'neg_adj': ['monotonous',\n",
       "  'convoluted',\n",
       "  'non-functional',\n",
       "  'ignored',\n",
       "  'implausible',\n",
       "  'worst',\n",
       "  'similar',\n",
       "  'french',\n",
       "  'frozen',\n",
       "  'dissapointed',\n",
       "  'setting',\n",
       "  'strange',\n",
       "  'poor',\n",
       "  'reasonable',\n",
       "  'relevant',\n",
       "  'impossible',\n",
       "  'longer',\n",
       "  'worse',\n",
       "  'least',\n",
       "  'Babble',\n",
       "  'cant',\n",
       "  'terrible',\n",
       "  'little',\n",
       "  'second',\n",
       "  'common',\n",
       "  'useless',\n",
       "  'incompatible',\n",
       "  'previous',\n",
       "  'stupid',\n",
       "  'inadequate',\n",
       "  'like',\n",
       "  'weak']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg.lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13c92a8",
   "metadata": {},
   "source": [
    "# Usando os templates gerados pelo TemplateGenerator no CheckList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8402c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.editor import Editor\n",
    "from checklist.test_suite import TestSuite\n",
    "from checklist.test_types import MFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11c3fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicons = tg.lexicons\n",
    "templates = tg.template_texts\n",
    "masked = tg.masked_texts\n",
    "labels = [sent.prediction.label for sent in tg.sentences]\n",
    "\n",
    "editor = Editor()\n",
    "editor.add_lexicon('pos_verb', lexicons['pos_verb'])\n",
    "editor.add_lexicon('neg_verb', lexicons['neg_verb'])\n",
    "editor.add_lexicon('pos_adj', lexicons['pos_adj'])\n",
    "editor.add_lexicon('neg_adj', lexicons['neg_adj'])\n",
    "\n",
    "suite = TestSuite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6528353",
   "metadata": {},
   "outputs": [],
   "source": [
    "for template, label, i in zip(templates, labels, range(len(templates))):\n",
    "    t = editor.template(template, remove_duplicates=True, labels=int(label))\n",
    "\n",
    "    suite.add(MFT(\n",
    "        data=t.data,\n",
    "        labels=label,\n",
    "        capability=\"Vocabullary\", \n",
    "        name=f\"Test: MFT with vocabullary - template{i+1}\",\n",
    "        description=\"Checking if the model can handle vocabullary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0909b6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test: MFT with vocabullary - template1\n",
      "Predicting 987 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28248/1831943719.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = softmax(tensor_logits[0]).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test: MFT with vocabullary - template2\n",
      "Predicting 987 examples\n",
      "Running Test: MFT with vocabullary - template3\n",
      "Predicting 1503 examples\n",
      "Running Test: MFT with vocabullary - template4\n",
      "Predicting 1503 examples\n",
      "Running Test: MFT with vocabullary - template5\n",
      "Predicting 1034 examples\n",
      "Running Test: MFT with vocabullary - template6\n",
      "Predicting 47 examples\n",
      "Running Test: MFT with vocabullary - template7\n",
      "Predicting 47 examples\n",
      "Running Test: MFT with vocabullary - template8\n",
      "Predicting 1034 examples\n",
      "Running Test: MFT with vocabullary - template9\n",
      "Predicting 704 examples\n",
      "Running Test: MFT with vocabullary - template10\n",
      "Predicting 1503 examples\n",
      "Running Test: MFT with vocabullary - template11\n",
      "Predicting 1503 examples\n",
      "Running Test: MFT with vocabullary - template12\n",
      "Predicting 32 examples\n",
      "Running Test: MFT with vocabullary - template13\n",
      "Predicting 987 examples\n",
      "Running Test: MFT with vocabullary - template14\n",
      "Predicting 462 examples\n",
      "Running Test: MFT with vocabullary - template15\n",
      "Predicting 987 examples\n",
      "Running Test: MFT with vocabullary - template16\n",
      "Predicting 987 examples\n",
      "Running Test: MFT with vocabullary - template17\n",
      "Predicting 1034 examples\n",
      "Running Test: MFT with vocabullary - template18\n",
      "Predicting 987 examples\n",
      "Running Test: MFT with vocabullary - template19\n",
      "Predicting 1503 examples\n",
      "Running Test: MFT with vocabullary - template20\n",
      "Predicting 672 examples\n",
      "Running Test: MFT with vocabullary - template21\n",
      "Predicting 987 examples\n",
      "Running Test: MFT with vocabullary - template22\n",
      "Predicting 987 examples\n",
      "Running Test: MFT with vocabullary - template23\n",
      "Predicting 1503 examples\n",
      "Running Test: MFT with vocabullary - template24\n",
      "Predicting 462 examples\n",
      "Running Test: MFT with vocabullary - template25\n",
      "Predicting 672 examples\n",
      "Running Test: MFT with vocabullary - template26\n",
      "Predicting 672 examples\n",
      "Running Test: MFT with vocabullary - template27\n",
      "Predicting 1034 examples\n",
      "Running Test: MFT with vocabullary - template28\n",
      "Predicting 32 examples\n",
      "Running Test: MFT with vocabullary - template29\n",
      "Predicting 1034 examples\n",
      "Running Test: MFT with vocabullary - template30\n",
      "Predicting 1503 examples\n",
      "Running Test: MFT with vocabullary - template31\n",
      "Predicting 987 examples\n",
      "Running Test: MFT with vocabullary - template32\n",
      "Predicting 987 examples\n",
      "Running Test: MFT with vocabullary - template33\n",
      "Predicting 47 examples\n",
      "Running Test: MFT with vocabullary - template34\n",
      "Predicting 462 examples\n",
      "Running Test: MFT with vocabullary - template35\n",
      "Predicting 987 examples\n",
      "Running Test: MFT with vocabullary - template36\n",
      "Predicting 1503 examples\n",
      "Running Test: MFT with vocabullary - template37\n",
      "Predicting 22 examples\n",
      "Running Test: MFT with vocabullary - template38\n",
      "Predicting 1503 examples\n",
      "Running Test: MFT with vocabullary - template39\n",
      "Predicting 987 examples\n",
      "Running Test: MFT with vocabullary - template40\n",
      "Predicting 47 examples\n",
      "Running Test: MFT with vocabullary - template41\n",
      "Predicting 1503 examples\n",
      "Running Test: MFT with vocabullary - template42\n",
      "Predicting 1503 examples\n",
      "Running Test: MFT with vocabullary - template43\n",
      "Predicting 1503 examples\n",
      "Running Test: MFT with vocabullary - template44\n",
      "Predicting 32 examples\n",
      "Running Test: MFT with vocabullary - template45\n",
      "Predicting 987 examples\n",
      "Running Test: MFT with vocabullary - template46\n",
      "Predicting 1503 examples\n",
      "Running Test: MFT with vocabullary - template47\n",
      "Predicting 1503 examples\n",
      "Running Test: MFT with vocabullary - template48\n",
      "Predicting 1034 examples\n",
      "Running Test: MFT with vocabullary - template49\n",
      "Predicting 704 examples\n",
      "Running Test: MFT with vocabullary - template50\n",
      "Predicting 987 examples\n",
      "Running Test: MFT with vocabullary - template51\n",
      "Predicting 1503 examples\n",
      "Running Test: MFT with vocabullary - template52\n",
      "Predicting 47 examples\n",
      "Running Test: MFT with vocabullary - template53\n",
      "Predicting 987 examples\n",
      "Running Test: MFT with vocabullary - template54\n",
      "Predicting 47 examples\n",
      "Running Test: MFT with vocabullary - template55\n",
      "Predicting 704 examples\n",
      "Running Test: MFT with vocabullary - template56\n",
      "Predicting 672 examples\n",
      "Running Test: MFT with vocabullary - template57\n",
      "Predicting 22 examples\n",
      "Running Test: MFT with vocabullary - template58\n",
      "Predicting 22 examples\n",
      "Running Test: MFT with vocabullary - template59\n",
      "Predicting 1503 examples\n",
      "Running Test: MFT with vocabullary - template60\n",
      "Predicting 987 examples\n",
      "Running Test: MFT with vocabullary - template61\n",
      "Predicting 987 examples\n",
      "Running Test: MFT with vocabullary - template62\n",
      "Predicting 1503 examples\n",
      "Running Test: MFT with vocabullary - template63\n",
      "Predicting 1503 examples\n",
      "Running Test: MFT with vocabullary - template64\n",
      "Predicting 987 examples\n",
      "Running Test: MFT with vocabullary - template65\n",
      "Predicting 672 examples\n",
      "Running Test: MFT with vocabullary - template66\n",
      "Predicting 987 examples\n",
      "Running Test: MFT with vocabullary - template67\n",
      "Predicting 47 examples\n",
      "Running Test: MFT with vocabullary - template68\n",
      "Predicting 987 examples\n",
      "Running Test: MFT with vocabullary - template69\n",
      "Predicting 47 examples\n",
      "Running Test: MFT with vocabullary - template70\n",
      "Predicting 704 examples\n",
      "Running Test: MFT with vocabullary - template71\n",
      "Predicting 1034 examples\n",
      "Running Test: MFT with vocabullary - template72\n",
      "Predicting 1034 examples\n",
      "Running Test: MFT with vocabullary - template73\n",
      "Predicting 47 examples\n",
      "Running Test: MFT with vocabullary - template74\n",
      "Predicting 1503 examples\n",
      "Running Test: MFT with vocabullary - template75\n",
      "Predicting 1503 examples\n",
      "Running Test: MFT with vocabullary - template76\n",
      "Predicting 47 examples\n",
      "Running Test: MFT with vocabullary - template77\n",
      "Predicting 672 examples\n",
      "Running Test: MFT with vocabullary - template78\n",
      "Predicting 47 examples\n",
      "Running Test: MFT with vocabullary - template79\n",
      "Predicting 47 examples\n",
      "Running Test: MFT with vocabullary - template80\n",
      "Predicting 462 examples\n",
      "Running Test: MFT with vocabullary - template81\n",
      "Predicting 32 examples\n",
      "Running Test: MFT with vocabullary - template82\n",
      "Predicting 1034 examples\n"
     ]
    }
   ],
   "source": [
    "suite.run(model.predict, overwrite=True)\n",
    "suite.save('./suites/posneg-approach3.suite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd47047c",
   "metadata": {},
   "source": [
    "# Carregando suite de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2f32103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.test_suite import TestSuite\n",
    "suite = TestSuite.from_file('./suites/posneg-approach3.suite')\n",
    "\n",
    "# suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "748db31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed = 14442 (21.06%)\n",
      "passed = 54118 (78.94%)\n",
      "total = 68560\n",
      "templates: 82\n"
     ]
    }
   ],
   "source": [
    "passed = 0\n",
    "failed = 0\n",
    "for test_name in suite.tests:\n",
    "    table = suite.visual_summary_by_test(test_name)\n",
    "    \n",
    "    failed += table.stats['nfailed']    \n",
    "    passed += table.stats['npassed']\n",
    "    assert table.stats['nfailed'] + table.stats['npassed'] == len(table.filtered_testcases)\n",
    "\n",
    "print(f\"{failed = } ({(failed/(passed+failed))*100:.2f}%)\")\n",
    "print(f\"{passed = } ({(passed/(passed+failed))*100:.2f}%)\")\n",
    "print(f\"total = {passed+failed}\")\n",
    "print(\"templates:\", len(suite.tests))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "335f8eac43d2678591a8076d8dfd5de078961fe9395efec4dfbbe61965ca9377"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
