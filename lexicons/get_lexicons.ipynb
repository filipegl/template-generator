{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = \"../notebooks_rotten_tomatoes_spacy/generated_templates/\"\n",
    "neg_verb = list()\n",
    "neg_adj = list()\n",
    "pos_verb = list()\n",
    "pos_adj = list()\n",
    "\n",
    "for filename in sorted(os.listdir(dirpath)):\n",
    "    df = pd.read_csv(os.path.join(dirpath, filename))\n",
    "    for _, row in df.iterrows():\n",
    "        if \"neg_adj\" in row[\"template_text\"]:\n",
    "            neg_adj.append((row['original_text'], row[\"template_text\"]))\n",
    "        if \"neg_verb\" in row[\"template_text\"]:\n",
    "            neg_verb.append((row['original_text'], row[\"template_text\"]))\n",
    "        if \"pos_verb\" in row[\"template_text\"]:\n",
    "            pos_verb.append((row['original_text'], row[\"template_text\"]))\n",
    "        if \"pos_adj\" in row[\"template_text\"]:\n",
    "            pos_adj.append((row['original_text'], row[\"template_text\"]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mask_braces(text):\n",
    "    text = re.sub(\"{pos_adj}\", \"pos_adj\", text)\n",
    "    text = re.sub(\"{neg_adj}\", \"neg_adj\", text)\n",
    "    text = re.sub(\"{pos_verb}\", \"pos_verb\", text)\n",
    "    text = re.sub(\"{neg_verb}\", \"neg_verb\", text)\n",
    "    return text\n",
    "\n",
    "def get_replaced_words(template: str, instance: str, tag: str=None):\n",
    "    \"\"\"\n",
    "    Compare both template and instance words to find the words that were replaced.\n",
    "    It returns a list of replaced words.\n",
    "    \"\"\"\n",
    "    # its necessary to use the same tokenizer of TemplateGenerator\n",
    "    temp_tokens = [token.text for token in nlp(remove_mask_braces(template))]\n",
    "    inst_tokens = [token.text for token in nlp(instance)]\n",
    "    \n",
    "    if len(temp_tokens) != len(inst_tokens):\n",
    "        temp_tokens = remove_mask_braces(template).split()\n",
    "        inst_tokens = instance.split()\n",
    "    \n",
    "    if len(temp_tokens) != len(inst_tokens):\n",
    "        print(f\"ADD TO {tag} the word:\")\n",
    "        print(f\"{template=}\")\n",
    "        print(f\"{instance=}\")\n",
    "        return []\n",
    "        # assert False\n",
    "    if tag:\n",
    "        get_token_condition = lambda i: temp_tokens[i] != inst_tokens[i] and temp_tokens[i] == tag\n",
    "    else:\n",
    "        get_token_condition = lambda i: temp_tokens[i] != inst_tokens[i]\n",
    "    \n",
    "    return [inst_tokens[i] for i in range(len(temp_tokens)) if get_token_condition(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_verbs = list()\n",
    "for a, b in neg_verb:\n",
    "    neg_verbs += get_replaced_words(b, a, \"neg_verb\")\n",
    "neg_verbs = list(set(neg_verbs))\n",
    "\n",
    "pos_verbs = list()\n",
    "for a, b in pos_verb:\n",
    "    pos_verbs += get_replaced_words(b, a, \"pos_verb\")\n",
    "pos_verbs = list(set(pos_verbs))\n",
    "\n",
    "neg_adjs = list()\n",
    "for a, b in neg_adj:\n",
    "    neg_adjs += get_replaced_words(b, a, \"neg_adj\")\n",
    "neg_adjs = list(set(neg_adjs))\n",
    "\n",
    "pos_adjs = list()\n",
    "for a, b in pos_adj:\n",
    "    pos_adjs += get_replaced_words(b, a, \"pos_adj\")\n",
    "pos_adjs = list(set(pos_adjs))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # IMDB_SPACY\n",
    "# neg_verbs += [\"reading\", \"do\", \"seen\"]\n",
    "# pos_verbs += [\"felt\", \"enjoy\"]\n",
    "# neg_adjs += [\"worst\"]\n",
    "# pos_adjs += [\"precious\", \"great\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_to_dict = {\n",
    "    \"neg_verbs\": neg_verbs,\n",
    "    \"pos_verbs\": pos_verbs,\n",
    "    \"pos_adjs\": pos_adjs,\n",
    "    \"neg_adjs\": neg_adjs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"rotten_tomatoes_all_lexicons.json\", \"wt\") as f:\n",
    "    json.dump(lex_to_dict, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "checklist-tg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
