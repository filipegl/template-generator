{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0e2c728",
   "metadata": {},
   "source": [
    "# Abordagem 1\n",
    "\n",
    "Usando a abordagem 1 para gerar templates com foco em templates positivos e negativos. Uma possível aplicação seria testar a capacidade linguística *Vocabullary* com o teste **MFT**.\n",
    "\n",
    "As etapas desta abordagem são:\n",
    "\n",
    "1. Rankear as palavras das instâncias completas\n",
    "2. Quebrar as instâncias em sentenças\n",
    "3. Filtrar as sentenças que contêm ao menos uma das palavras mais bem rankeadas na etapa anterior\n",
    "4. Filtrar as sentenças com palavras relevantes (adjetivos ou verbos)\n",
    "5. Classificar as sentenças usando o *Oráculo*\n",
    "6. Filtrar as sentenças classificadas de forma unânime\n",
    "7. Substituir as palavras relevantes por máscaras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "897c3a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da847fc",
   "metadata": {},
   "source": [
    "## Carregando o dataset, o modelo alvo e os modelos auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e018fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unpretentious , charming , quirky , original</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a film really has to be exceptional to justify a three hour running time , and this isn't .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>working from a surprisingly sensitive script co-written by gianni romoli . . . ozpetek avoids most of the pitfalls you'd expect in such a potentially sudsy set-up .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it may not be particularly innovative , but the film's crisp , unaffected style and air of gentle longing make it unexpectedly rewarding .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>such a premise is ripe for all manner of lunacy , but kaufman and gondry rarely seem sure of where it should go .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ice age is the first computer-generated feature cartoon to feel like other movies , and that makes for some glacial pacing early on .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>there's no denying that burns is a filmmaker with a bright future ahead of him .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>it collapses when mr . taylor tries to shift the tone to a thriller's rush .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>there's a great deal of corny dialogue and preposterous moments . and yet , it still works .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ah , the travails of metropolitan life ! alas , another breathless movie about same !</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                    text  \\\n",
       "0                                                                                                                           unpretentious , charming , quirky , original   \n",
       "1                                                                            a film really has to be exceptional to justify a three hour running time , and this isn't .   \n",
       "2   working from a surprisingly sensitive script co-written by gianni romoli . . . ozpetek avoids most of the pitfalls you'd expect in such a potentially sudsy set-up .   \n",
       "3                             it may not be particularly innovative , but the film's crisp , unaffected style and air of gentle longing make it unexpectedly rewarding .   \n",
       "4                                                      such a premise is ripe for all manner of lunacy , but kaufman and gondry rarely seem sure of where it should go .   \n",
       "..                                                                                                                                                                   ...   \n",
       "95                                 ice age is the first computer-generated feature cartoon to feel like other movies , and that makes for some glacial pacing early on .   \n",
       "96                                                                                      there's no denying that burns is a filmmaker with a bright future ahead of him .   \n",
       "97                                                                                          it collapses when mr . taylor tries to shift the tone to a thriller's rush .   \n",
       "98                                                                          there's a great deal of corny dialogue and preposterous moments . and yet , it still works .   \n",
       "99                                                                                 ah , the travails of metropolitan life ! alas , another breathless movie about same !   \n",
       "\n",
       "    label  \n",
       "0       1  \n",
       "1       0  \n",
       "2       1  \n",
       "3       1  \n",
       "4       0  \n",
       "..    ...  \n",
       "95      0  \n",
       "96      1  \n",
       "97      0  \n",
       "98      1  \n",
       "99      0  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "dataset.set_format(\"pandas\")\n",
    "df = dataset[\"test\"].shuffle(seed=42)[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52d451cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    51\n",
       "1    49\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "264d0dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from torch.nn.functional import softmax\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "def pre_proccess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[\"\\',!-.:-@0-9/]()', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Wrapper to adapt output format\n",
    "class SentimentAnalisysModelWrapper:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __predict(self, text_input):\n",
    "        text_preprocessed = pre_proccess(text_input)\n",
    "        tokenized = self.tokenizer(text_preprocessed, padding=True, truncation=True, max_length=512, \n",
    "                                    add_special_tokens = True, return_tensors=\"pt\")\n",
    "        \n",
    "        tensor_logits = self.model(**tokenized)\n",
    "        prob = softmax(tensor_logits[0]).detach().numpy()\n",
    "        pred = np.argmax(prob)\n",
    "        \n",
    "        return pred, prob\n",
    "    \n",
    "    def predict_label(self, text_inputs):\n",
    "        return self.predict(text_inputs)[0]\n",
    "        \n",
    "    def predict_proba(self, text_inputs):\n",
    "        return self.predict(text_inputs)[1]\n",
    "        \n",
    "    def predict(self, text_inputs):\n",
    "        if isinstance(text_inputs, str):\n",
    "            text_inputs = [text_inputs]\n",
    "        \n",
    "        preds = []\n",
    "        probs = []\n",
    "\n",
    "        for text_input in text_inputs:\n",
    "            pred, prob = self.__predict(text_input)\n",
    "            preds.append(pred)\n",
    "            probs.append(prob[0])\n",
    "\n",
    "        return np.array(preds), np.array(probs) # ([0, 1], [[0.99, 0.01], [0.03, 0.97]])\n",
    "\n",
    "# Auxiliar function to load and wrap a model from Hugging Face\n",
    "def load_model(model_name):\n",
    "    print(f'Loading model {model_name}...')\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    return SentimentAnalisysModelWrapper(model, tokenizer)\n",
    "\n",
    "# Hugging Face hosted model names \n",
    "rotten_tomatoes_models = {\n",
    "    'bert': 'textattack/bert-base-uncased-rotten-tomatoes', \n",
    "    'albert': 'textattack/albert-base-v2-rotten-tomatoes', \n",
    "    'distilbert': 'textattack/distilbert-base-uncased-rotten-tomatoes', \n",
    "    'roberta': 'textattack/roberta-base-rotten-tomatoes', \n",
    "    'xlnet': 'textattack/xlnet-base-cased-rotten-tomatoes', \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f271eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model textattack/albert-base-v2-rotten-tomatoes...\n",
      "Loading model textattack/distilbert-base-uncased-rotten-tomatoes...\n",
      "Loading model textattack/roberta-base-rotten-tomatoes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-rotten-tomatoes were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model textattack/xlnet-base-cased-rotten-tomatoes...\n",
      "Loading model textattack/bert-base-uncased-rotten-tomatoes...\n"
     ]
    }
   ],
   "source": [
    "m1 = load_model(rotten_tomatoes_models['albert'])\n",
    "m2 = load_model(rotten_tomatoes_models['distilbert'])\n",
    "m3 = load_model(rotten_tomatoes_models['roberta'])\n",
    "m4 = load_model(rotten_tomatoes_models['xlnet'])\n",
    "\n",
    "# Models to be used as oracle\n",
    "models = [m1, m2, m3, m4]\n",
    "# Target model\n",
    "model = load_model(rotten_tomatoes_models['bert'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caae89b5",
   "metadata": {},
   "source": [
    "# Gerando os templates\n",
    "O método de rankeamento das palavras usado no PosNegTemplateGenerator é o Replace-1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60dc1af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from template_generator.tasks.sentiment_analisys import PosNegTemplateGeneratorApp1\n",
    "\n",
    "tg = PosNegTemplateGeneratorApp1(model, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f595e69",
   "metadata": {},
   "source": [
    "### Número inicial de instâncias: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6261506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the rules of attraction gets us too drunk on the party favors to sober us up with the transparent attempts at moralizing .',\n",
       " \"cherry orchard is badly edited , often awkwardly directed and suffers from the addition of a wholly unnecessary pre-credit sequence designed to give some of the characters a 'back story . '\",\n",
       " \"there is more than one joke about putting the toilet seat down . and that should tell you everything you need to know about all the queen's men .\",\n",
       " \"the high-concept scenario soon proves preposterous , the acting is robotically italicized , and truth-in-advertising hounds take note : there's very little hustling on view .\",\n",
       " \"it may not be particularly innovative , but the film's crisp , unaffected style and air of gentle longing make it unexpectedly rewarding .\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sampling instances\n",
    "np.random.seed(220)\n",
    "n_instances = 5\n",
    "df_sampled = df.sample(n_instances)\n",
    "\n",
    "instances = [x for x in df_sampled['text'].values]\n",
    "instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "660add17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking words using Replace-1 Score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6738/4227237112.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = softmax(tensor_logits[0]).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting texts to sentences...\n",
      ":: 5 sentences were generated.\n",
      "Filtering instances by contaning ranked words...\n",
      ":: 0 sentences remaining.\n",
      "Filtering instances by relevant words...\n",
      ":: 0 sentences remaining.\n",
      "Predicting inputs...\n",
      ":: Sentence predictions done.\n"
     ]
    }
   ],
   "source": [
    "templates = tg.generate_templates(instances)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72d150cb",
   "metadata": {},
   "source": [
    "#### Tempo de execução para 5 instâncias: 6m 8.6s\n",
    "filipe: 2m 20.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "193f1b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>original_text</th>\n",
       "      <th>masked_text</th>\n",
       "      <th>template_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [label, original_text, masked_text, template_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f98d8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_verb': [], 'neg_verb': [], 'pos_adj': [], 'neg_adj': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg.lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a27f1f",
   "metadata": {},
   "source": [
    "### Número inicial de instâncias: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd4a7fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using all 100 instances\n",
    "instances = [x for x in df['text'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1f3f383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking words using Replace-1 Score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6738/4227237112.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = softmax(tensor_logits[0]).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting texts to sentences...\n",
      ":: 103 sentences were generated.\n",
      "Filtering instances by contaning ranked words...\n",
      ":: 3 sentences remaining.\n",
      "Filtering instances by relevant words...\n",
      ":: 0 sentences remaining.\n",
      "Predicting inputs...\n",
      ":: Sentence predictions done.\n",
      "CPU times: user 14min 44s, sys: 1.75 s, total: 14min 46s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 1m 38.7s (com outros processos pesados concorrendo, isso opde ter diminuido)\n",
    "tg = PosNegTemplateGeneratorApp1(model, models)\n",
    "templates = tg.generate_templates(instances)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2aaf7e38",
   "metadata": {},
   "source": [
    "#### Tempo de execução para 100 instâncias: 1m 0.7s\n",
    "filipe: 1m 0.7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c3c1541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>template_index</th>\n",
       "      <th>label</th>\n",
       "      <th>original_text</th>\n",
       "      <th>masked_text</th>\n",
       "      <th>template_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [template_index, label, original_text, masked_text, template_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_templates = tg.to_dataframe()\n",
    "df_templates.insert(0, \"template_index\", df_templates.index.map(lambda x: int(x)+1))\n",
    "df_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d3ddb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_templates.to_csv(\"generated_templates/generated_templates_approach1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0571a42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_verb': [], 'neg_verb': [], 'pos_adj': [], 'neg_adj': []}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg.lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c105889",
   "metadata": {},
   "source": [
    "# Usando os templates gerados pelo TemplateGenerator no CheckList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "263ea542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.editor import Editor\n",
    "from checklist.test_suite import TestSuite\n",
    "from checklist.test_types import MFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "017ec5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicons = tg.lexicons\n",
    "templates = tg.template_texts\n",
    "masked = tg.masked_texts\n",
    "labels = [sent.prediction.label for sent in tg.sentences]\n",
    "\n",
    "editor = Editor()\n",
    "editor.add_lexicon('pos_verb', lexicons['pos_verb'])\n",
    "editor.add_lexicon('neg_verb', lexicons['neg_verb'])\n",
    "editor.add_lexicon('pos_adj', lexicons['pos_adj'])\n",
    "editor.add_lexicon('neg_adj', lexicons['neg_adj'])\n",
    "\n",
    "suite = TestSuite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25f75255",
   "metadata": {},
   "outputs": [],
   "source": [
    "for template, label, i in zip(templates, labels, range(len(templates))):\n",
    "    t = editor.template(template, remove_duplicates=True, labels=int(label))\n",
    "\n",
    "    suite.add(MFT(\n",
    "        data=t.data,\n",
    "        labels=label,\n",
    "        capability=\"Vocabullary\", \n",
    "        name=f\"Test: MFT with vocabullary - template{i+1}\",\n",
    "        description=\"Checking if the model can handle vocabullary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe3d0885",
   "metadata": {},
   "outputs": [],
   "source": [
    "suite.run(model.predict, overwrite=True)\n",
    "suite.save('./suites/posneg-approach1.suite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33065add",
   "metadata": {},
   "source": [
    "# Carregando suite de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "563d7be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.test_suite import TestSuite\n",
    "suite = TestSuite.from_file('./suites/posneg-approach1.suite')\n",
    "\n",
    "# suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c10c0b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/filipegl/Documents/template-generator/notebooks_rotten_tomatoes_spacy/generating_templates_posneg_approach1.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/filipegl/Documents/template-generator/notebooks_rotten_tomatoes_spacy/generating_templates_posneg_approach1.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     passed \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m table\u001b[39m.\u001b[39mstats[\u001b[39m'\u001b[39m\u001b[39mnpassed\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/filipegl/Documents/template-generator/notebooks_rotten_tomatoes_spacy/generating_templates_posneg_approach1.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39massert\u001b[39;00m table\u001b[39m.\u001b[39mstats[\u001b[39m'\u001b[39m\u001b[39mnfailed\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m table\u001b[39m.\u001b[39mstats[\u001b[39m'\u001b[39m\u001b[39mnpassed\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(table\u001b[39m.\u001b[39mfiltered_testcases)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/filipegl/Documents/template-generator/notebooks_rotten_tomatoes_spacy/generating_templates_posneg_approach1.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfailed\u001b[39m \u001b[39m\u001b[39m= }\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00m(failed\u001b[39m/\u001b[39;49m(passed\u001b[39m+\u001b[39;49mfailed))\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/filipegl/Documents/template-generator/notebooks_rotten_tomatoes_spacy/generating_templates_posneg_approach1.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m \u001b[39m\u001b[39m= }\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00m(passed\u001b[39m/\u001b[39m(passed\u001b[39m+\u001b[39mfailed))\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/filipegl/Documents/template-generator/notebooks_rotten_tomatoes_spacy/generating_templates_posneg_approach1.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtotal = \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m+\u001b[39mfailed\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "passed = 0\n",
    "failed = 0\n",
    "for test_name in suite.tests:\n",
    "    table = suite.visual_summary_by_test(test_name)\n",
    "    \n",
    "    failed += table.stats['nfailed']    \n",
    "    passed += table.stats['npassed']\n",
    "    assert table.stats['nfailed'] + table.stats['npassed'] == len(table.filtered_testcases)\n",
    "\n",
    "print(f\"{failed = } ({(failed/(passed+failed))*100:.2f}%)\")\n",
    "print(f\"{passed = } ({(passed/(passed+failed))*100:.2f}%)\")\n",
    "print(f\"total = {passed+failed}\")\n",
    "print(\"templates:\", len(suite.tests))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc9a1fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'examples': [{'new': {'text': \"and that should need you everything you need to know about all the queen 's men .\",\n",
       "     'pred': '0',\n",
       "     'conf': 0.6925088,\n",
       "     'tokens': [['and',\n",
       "       'that',\n",
       "       'should',\n",
       "       'need',\n",
       "       'you',\n",
       "       'everything',\n",
       "       'you',\n",
       "       'need',\n",
       "       'to',\n",
       "       'know',\n",
       "       'about',\n",
       "       'all',\n",
       "       'the',\n",
       "       'queen',\n",
       "       \"'s\",\n",
       "       'men',\n",
       "       '.']]},\n",
       "    'old': None,\n",
       "    'label': 1,\n",
       "    'succeed': 0}],\n",
       "  'succeed': 0,\n",
       "  'tags': []}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.candidate_testcases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e951a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'examples': [{'new': {'text': \"and that should tell you everything you tell to know about all the queen 's men .\",\n",
       "     'pred': '1',\n",
       "     'conf': 0.9949285,\n",
       "     'tokens': [['and',\n",
       "       'that',\n",
       "       'should',\n",
       "       'tell',\n",
       "       'you',\n",
       "       'everything',\n",
       "       'you',\n",
       "       'tell',\n",
       "       'to',\n",
       "       'know',\n",
       "       'about',\n",
       "       'all',\n",
       "       'the',\n",
       "       'queen',\n",
       "       \"'s\",\n",
       "       'men',\n",
       "       '.']]},\n",
       "    'old': None,\n",
       "    'label': 1,\n",
       "    'succeed': 1}],\n",
       "  'succeed': 1,\n",
       "  'tags': []},\n",
       " {'examples': [{'new': {'text': \"and that should need you everything you need to know about all the queen 's men .\",\n",
       "     'pred': '0',\n",
       "     'conf': 0.6925088,\n",
       "     'tokens': [['and',\n",
       "       'that',\n",
       "       'should',\n",
       "       'need',\n",
       "       'you',\n",
       "       'everything',\n",
       "       'you',\n",
       "       'need',\n",
       "       'to',\n",
       "       'know',\n",
       "       'about',\n",
       "       'all',\n",
       "       'the',\n",
       "       'queen',\n",
       "       \"'s\",\n",
       "       'men',\n",
       "       '.']]},\n",
       "    'old': None,\n",
       "    'label': 1,\n",
       "    'succeed': 0}],\n",
       "  'succeed': 0,\n",
       "  'tags': []}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.filtered_testcases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "parental-shelter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'new': {'text': \"and that should tell you everything you tell to know about all the queen 's men .\", 'pred': '1', 'conf': 0.9949285, 'tokens': [['and', 'that', 'should', 'tell', 'you', 'everything', 'you', 'tell', 'to', 'know', 'about', 'all', 'the', 'queen', \"'s\", 'men', '.']]}, 'old': None, 'label': 1, 'succeed': 1}\n",
      "{'new': {'text': \"and that should need you everything you need to know about all the queen 's men .\", 'pred': '0', 'conf': 0.6925088, 'tokens': [['and', 'that', 'should', 'need', 'you', 'everything', 'you', 'need', 'to', 'know', 'about', 'all', 'the', 'queen', \"'s\", 'men', '.']]}, 'old': None, 'label': 1, 'succeed': 0}\n"
     ]
    }
   ],
   "source": [
    "table = suite.visual_summary_by_test('Test: MFT with vocabullary - template1')\n",
    "\n",
    "failed = table.candidate_testcases\n",
    "tests = table.filtered_testcases\n",
    "\n",
    "for item in tests:\n",
    "    # if not item in failed:\n",
    "    print(item['examples'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29dedfd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(table.candidate_testcases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c15ea5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__class__',\n",
       " '__del__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_active_widgets',\n",
       " '_add_notifiers',\n",
       " '_all_trait_default_generators',\n",
       " '_call_widget_constructed',\n",
       " '_comm_changed',\n",
       " '_compare',\n",
       " '_control_comm',\n",
       " '_cross_validation_lock',\n",
       " '_default_keys',\n",
       " '_descriptors',\n",
       " '_dom_classes',\n",
       " '_gen_repr_from_keys',\n",
       " '_get_embed_state',\n",
       " '_get_trait_default_generator',\n",
       " '_handle_control_comm_msg',\n",
       " '_handle_custom_msg',\n",
       " '_handle_msg',\n",
       " '_holding_sync',\n",
       " '_instance_inits',\n",
       " '_is_numpy',\n",
       " '_lock_property',\n",
       " '_log_default',\n",
       " '_model_id',\n",
       " '_model_module',\n",
       " '_model_module_version',\n",
       " '_model_name',\n",
       " '_msg_callbacks',\n",
       " '_notify_observers',\n",
       " '_notify_trait',\n",
       " '_property_lock',\n",
       " '_register_validator',\n",
       " '_remove_notifiers',\n",
       " '_repr_keys',\n",
       " '_repr_mimebundle_',\n",
       " '_send',\n",
       " '_should_send_property',\n",
       " '_states_to_send',\n",
       " '_static_immutable_initial_values',\n",
       " '_trait_default_generators',\n",
       " '_trait_from_json',\n",
       " '_trait_notifiers',\n",
       " '_trait_to_json',\n",
       " '_trait_validators',\n",
       " '_trait_values',\n",
       " '_traits',\n",
       " '_view_count',\n",
       " '_view_module',\n",
       " '_view_module_version',\n",
       " '_view_name',\n",
       " '_widget_construction_callback',\n",
       " '_widget_types',\n",
       " 'add_class',\n",
       " 'add_traits',\n",
       " 'blur',\n",
       " 'candidate_testcases',\n",
       " 'class_own_trait_events',\n",
       " 'class_own_traits',\n",
       " 'class_trait_names',\n",
       " 'class_traits',\n",
       " 'close',\n",
       " 'close_all',\n",
       " 'comm',\n",
       " 'compute_stats_result',\n",
       " 'cross_validation_lock',\n",
       " 'fetch_example',\n",
       " 'filtered_testcases',\n",
       " 'focus',\n",
       " 'get_manager_state',\n",
       " 'get_state',\n",
       " 'get_view_spec',\n",
       " 'handle_comm_opened',\n",
       " 'handle_control_comm_opened',\n",
       " 'handle_events',\n",
       " 'has_trait',\n",
       " 'hold_sync',\n",
       " 'hold_trait_notifications',\n",
       " 'is_satisfy_filter',\n",
       " 'keys',\n",
       " 'layout',\n",
       " 'log',\n",
       " 'max_return',\n",
       " 'model_id',\n",
       " 'notify_change',\n",
       " 'observe',\n",
       " 'on_msg',\n",
       " 'on_trait_change',\n",
       " 'on_widget_constructed',\n",
       " 'open',\n",
       " 'remove_class',\n",
       " 'render',\n",
       " 'reset_summary',\n",
       " 'reset_testcases',\n",
       " 'search',\n",
       " 'send',\n",
       " 'send_state',\n",
       " 'set_state',\n",
       " 'set_trait',\n",
       " 'setup_instance',\n",
       " 'stats',\n",
       " 'summarizer',\n",
       " 'tabbable',\n",
       " 'testcases',\n",
       " 'to_slice_idx',\n",
       " 'tokenize_testcases',\n",
       " 'tokenizer',\n",
       " 'tooltip',\n",
       " 'trait_defaults',\n",
       " 'trait_events',\n",
       " 'trait_has_value',\n",
       " 'trait_metadata',\n",
       " 'trait_names',\n",
       " 'trait_values',\n",
       " 'traits',\n",
       " 'unobserve',\n",
       " 'unobserve_all',\n",
       " 'widget_types',\n",
       " 'widgets']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e25fe427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'npassed': 1, 'nfailed': 1, 'nfiltered': 0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.tokenize_testcases"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "335f8eac43d2678591a8076d8dfd5de078961fe9395efec4dfbbe61965ca9377"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
