{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0e2c728",
   "metadata": {},
   "source": [
    "# Abordagem 5\n",
    "\n",
    "Usando a abordagem 5 para gerar templates com foco em templates positivos e negativos. Uma possível aplicação seria testar a capacidade linguística \"Vocabulary\" com o teste MFT.\n",
    "\n",
    "As etapas desta abordagem são:\n",
    "\n",
    "1. Quebrar as instâncias em sentenças\n",
    "2. Rankear as palavras de cada sentença\n",
    "3. Filtrar as sentenças pelo tamanho (maior ou igual a 5 palavras)\n",
    "4. Filtrar sentenças com palavras relevantes (verbos ou adjetivos)\n",
    "5. Filtrar sentenças com alta confiança na predição das palavras relevantes da etapa anterior\n",
    "6. Substituir as palavras relevantes por máscaras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "897c3a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da847fc",
   "metadata": {},
   "source": [
    "## Carregando o dataset, o modelo alvo e os modelos auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e018fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unpretentious , charming , quirky , original</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a film really has to be exceptional to justify a three hour running time , and this isn't .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>working from a surprisingly sensitive script co-written by gianni romoli . . . ozpetek avoids most of the pitfalls you'd expect in such a potentially sudsy set-up .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it may not be particularly innovative , but the film's crisp , unaffected style and air of gentle longing make it unexpectedly rewarding .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>such a premise is ripe for all manner of lunacy , but kaufman and gondry rarely seem sure of where it should go .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ice age is the first computer-generated feature cartoon to feel like other movies , and that makes for some glacial pacing early on .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>there's no denying that burns is a filmmaker with a bright future ahead of him .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>it collapses when mr . taylor tries to shift the tone to a thriller's rush .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>there's a great deal of corny dialogue and preposterous moments . and yet , it still works .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ah , the travails of metropolitan life ! alas , another breathless movie about same !</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                    text  \\\n",
       "0                                                                                                                           unpretentious , charming , quirky , original   \n",
       "1                                                                            a film really has to be exceptional to justify a three hour running time , and this isn't .   \n",
       "2   working from a surprisingly sensitive script co-written by gianni romoli . . . ozpetek avoids most of the pitfalls you'd expect in such a potentially sudsy set-up .   \n",
       "3                             it may not be particularly innovative , but the film's crisp , unaffected style and air of gentle longing make it unexpectedly rewarding .   \n",
       "4                                                      such a premise is ripe for all manner of lunacy , but kaufman and gondry rarely seem sure of where it should go .   \n",
       "..                                                                                                                                                                   ...   \n",
       "95                                 ice age is the first computer-generated feature cartoon to feel like other movies , and that makes for some glacial pacing early on .   \n",
       "96                                                                                      there's no denying that burns is a filmmaker with a bright future ahead of him .   \n",
       "97                                                                                          it collapses when mr . taylor tries to shift the tone to a thriller's rush .   \n",
       "98                                                                          there's a great deal of corny dialogue and preposterous moments . and yet , it still works .   \n",
       "99                                                                                 ah , the travails of metropolitan life ! alas , another breathless movie about same !   \n",
       "\n",
       "    label  \n",
       "0       1  \n",
       "1       0  \n",
       "2       1  \n",
       "3       1  \n",
       "4       0  \n",
       "..    ...  \n",
       "95      0  \n",
       "96      1  \n",
       "97      0  \n",
       "98      1  \n",
       "99      0  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "dataset.set_format(\"pandas\")\n",
    "df = dataset[\"test\"].shuffle(seed=42)[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "264d0dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from torch.nn.functional import softmax\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "def pre_proccess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[\"\\',!-.:-@0-9/]()', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Wrapper to adapt output format\n",
    "class SentimentAnalisysModelWrapper:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __predict(self, text_input):\n",
    "        text_preprocessed = pre_proccess(text_input)\n",
    "        tokenized = self.tokenizer(text_preprocessed, padding=True, truncation=True, max_length=512, \n",
    "                                    add_special_tokens = True, return_tensors=\"pt\")\n",
    "        \n",
    "        tensor_logits = self.model(**tokenized)\n",
    "        prob = softmax(tensor_logits[0]).detach().numpy()\n",
    "        pred = np.argmax(prob)\n",
    "        \n",
    "        return pred, prob\n",
    "    \n",
    "    def predict_label(self, text_inputs):\n",
    "        return self.predict(text_inputs)[0]\n",
    "        \n",
    "    def predict_proba(self, text_inputs):\n",
    "        return self.predict(text_inputs)[1]\n",
    "        \n",
    "    def predict(self, text_inputs):\n",
    "        if isinstance(text_inputs, str):\n",
    "            text_inputs = [text_inputs]\n",
    "        \n",
    "        preds = []\n",
    "        probs = []\n",
    "\n",
    "        for text_input in text_inputs:\n",
    "            pred, prob = self.__predict(text_input)\n",
    "            preds.append(pred)\n",
    "            probs.append(prob[0])\n",
    "\n",
    "        return np.array(preds), np.array(probs) # ([0, 1], [[0.99, 0.01], [0.03, 0.97]])\n",
    "\n",
    "# Auxiliar function to load and wrap a model from Hugging Face\n",
    "def load_model(model_name):\n",
    "    print(f'Loading model {model_name}...')\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    return SentimentAnalisysModelWrapper(model, tokenizer)\n",
    "\n",
    "# Hugging Face hosted model names \n",
    "rotten_tomatoes_models = {\n",
    "    'bert': 'textattack/bert-base-uncased-rotten-tomatoes', \n",
    "    'albert': 'textattack/albert-base-v2-rotten-tomatoes', \n",
    "    'distilbert': 'textattack/distilbert-base-uncased-rotten-tomatoes', \n",
    "    'roberta': 'textattack/roberta-base-rotten-tomatoes', \n",
    "    'xlnet': 'textattack/xlnet-base-cased-rotten-tomatoes', \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f271eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model textattack/albert-base-v2-rotten-tomatoes...\n",
      "Loading model textattack/distilbert-base-uncased-rotten-tomatoes...\n",
      "Loading model textattack/roberta-base-rotten-tomatoes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-rotten-tomatoes were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model textattack/xlnet-base-cased-rotten-tomatoes...\n",
      "Loading model textattack/bert-base-uncased-rotten-tomatoes...\n"
     ]
    }
   ],
   "source": [
    "m1 = load_model(rotten_tomatoes_models['albert'])\n",
    "m2 = load_model(rotten_tomatoes_models['distilbert'])\n",
    "m3 = load_model(rotten_tomatoes_models['roberta'])\n",
    "m4 = load_model(rotten_tomatoes_models['xlnet'])\n",
    "\n",
    "# Models to be used as oracle\n",
    "models = [m1, m2, m3, m4]\n",
    "# Target model\n",
    "model = load_model(rotten_tomatoes_models['bert'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caae89b5",
   "metadata": {},
   "source": [
    "# Gerando os templates\n",
    "O método de rankeamento das palavras usado no PosNegTemplateGenerator é o Replace-1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60dc1af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from template_generator.tasks.sentiment_analisys import PosNegTemplateGeneratorApp5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f595e69",
   "metadata": {},
   "source": [
    "### Número inicial de instâncias: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6261506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling instances\n",
    "np.random.seed(220)\n",
    "n_instances = 5\n",
    "df_sampled = df.sample(n_instances)\n",
    "\n",
    "instances = [x for x in df_sampled['text'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "660add17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting texts to sentences...\n",
      ":: 5 sentences were generated.\n",
      "Ranking words using Replace-1 Score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10625/4227237112.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = softmax(tensor_logits[0]).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Word ranking done.\n",
      "Filtering instances by contaning a minimmum of words: 5...\n",
      ":: 5 sentences remaining.\n",
      "Filtering instances by relevant words...\n",
      ":: 3 sentences remaining.\n",
      "Filtering instances by relevant words classification score greater than 0.8\n",
      ":: 2 sentences remaining.\n",
      "Predicting inputs...\n",
      ":: Sentence predictions done.\n"
     ]
    }
   ],
   "source": [
    "tg = PosNegTemplateGeneratorApp5(model, models)\n",
    "templates = tg.generate_templates(instances, n_masks=2, ranked_words_count=4, min_classification_score=0.8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ff5c8cb",
   "metadata": {},
   "source": [
    "#### Tempo de execução para 5 instâncias: 1m 15.8s\n",
    "filipe: 41.6s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "193f1b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>original_text</th>\n",
       "      <th>masked_text</th>\n",
       "      <th>template_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>the rules of attraction gets us too drunk on the party favors to sober us up with the transparent attempts at moralizing .</td>\n",
       "      <td>the rules of attraction {mask} us too {mask} on the party favors to sober us up with the transparent attempts at moralizing .</td>\n",
       "      <td>the rules of attraction {pos_verb} us too {neg_adj} on the party favors to sober us up with the transparent attempts at moralizing .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>the high-concept scenario soon proves preposterous , the acting is robotically italicized , and truth-in-advertising hounds take note : there's very little hustling on view .</td>\n",
       "      <td>the high - concept scenario soon proves {mask} , the acting is robotically {mask} , and truth - in - advertising hounds take note : there 's very little hustling on view .</td>\n",
       "      <td>the high - concept scenario soon proves {neg_adj} , the acting is robotically {neg_verb} , and truth - in - advertising hounds take note : there 's very little hustling on view .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      0   \n",
       "1      0   \n",
       "\n",
       "                                                                                                                                                                    original_text  \\\n",
       "0                                                      the rules of attraction gets us too drunk on the party favors to sober us up with the transparent attempts at moralizing .   \n",
       "1  the high-concept scenario soon proves preposterous , the acting is robotically italicized , and truth-in-advertising hounds take note : there's very little hustling on view .   \n",
       "\n",
       "                                                                                                                                                                   masked_text  \\\n",
       "0                                                the rules of attraction {mask} us too {mask} on the party favors to sober us up with the transparent attempts at moralizing .   \n",
       "1  the high - concept scenario soon proves {mask} , the acting is robotically {mask} , and truth - in - advertising hounds take note : there 's very little hustling on view .   \n",
       "\n",
       "                                                                                                                                                                        template_text  \n",
       "0                                                the rules of attraction {pos_verb} us too {neg_adj} on the party favors to sober us up with the transparent attempts at moralizing .  \n",
       "1  the high - concept scenario soon proves {neg_adj} , the acting is robotically {neg_verb} , and truth - in - advertising hounds take note : there 's very little hustling on view .  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c03851be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_verb': ['gets'],\n",
       " 'neg_verb': ['italicized'],\n",
       " 'pos_adj': [],\n",
       " 'neg_adj': ['drunk', 'preposterous']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg.lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a27f1f",
   "metadata": {},
   "source": [
    "### Número inicial de instâncias: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd4a7fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using all 100 instances\n",
    "instances = [x for x in df['text'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1f3f383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting texts to sentences...\n",
      ":: 103 sentences were generated.\n",
      "Ranking words using Replace-1 Score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10625/4227237112.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = softmax(tensor_logits[0]).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Word ranking done.\n",
      "Filtering instances by contaning a minimmum of words: 5...\n",
      ":: 103 sentences remaining.\n",
      "Filtering instances by relevant words...\n",
      ":: 43 sentences remaining.\n",
      "Filtering instances by relevant words classification score greater than 0.8\n",
      ":: 26 sentences remaining.\n",
      "Predicting inputs...\n",
      ":: Sentence predictions done.\n",
      "CPU times: user 16min 13s, sys: 1.33 s, total: 16min 14s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 1m 47.3s\n",
    "tg = PosNegTemplateGeneratorApp5(model, models)\n",
    "templates = tg.generate_templates(instances, n_masks=2, ranked_words_count=4, min_classification_score=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677154d8",
   "metadata": {},
   "source": [
    "#### Tempo de execução para 100 instâncias: 1m 5.6s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c3c1541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>original_text</th>\n",
       "      <th>masked_text</th>\n",
       "      <th>template_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>unpretentious , charming , quirky , original</td>\n",
       "      <td>{mask} , charming , quirky , {mask}</td>\n",
       "      <td>{neg_adj} , charming , quirky , {neg_adj}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>working from a surprisingly sensitive script co-written by gianni romoli . . . ozpetek avoids most of the pitfalls you'd expect in such a potentially sudsy set-up .</td>\n",
       "      <td>working from a surprisingly {mask} script co - written by gianni romoli . . . ozpetek {mask} most of the pitfalls you 'd expect in such a potentially sudsy set - up .</td>\n",
       "      <td>working from a surprisingly {neg_adj} script co - written by gianni romoli . . . ozpetek {neg_verb} most of the pitfalls you 'd expect in such a potentially sudsy set - up .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>it's like a \" big chill \" reunion of the baader-meinhof gang , only these guys are more harmless pranksters than political activists .</td>\n",
       "      <td>it 's like a \" {mask} chill \" reunion of the baader - meinhof gang , only these guys are more {mask} pranksters than political activists .</td>\n",
       "      <td>it 's like a \" {neg_adj} chill \" reunion of the baader - meinhof gang , only these guys are more {neg_adj} pranksters than political activists .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>the stunt work is top-notch ; the dialogue and drama often food-spittingly funny .</td>\n",
       "      <td>the stunt work is top - {mask} ; the dialogue and drama often food - spittingly {mask} .</td>\n",
       "      <td>the stunt work is top - {pos_adj} ; the dialogue and drama often food - spittingly {pos_adj} .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>an original and highly cerebral examination of the psychopathic mind</td>\n",
       "      <td>an {mask} and highly cerebral examination of the {mask} mind</td>\n",
       "      <td>an {neg_adj} and highly cerebral examination of the {neg_adj} mind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>a rip-off twice removed , modeled after [seagal's] earlier copycat under siege , sometimes referred to as die hard on a boat .</td>\n",
       "      <td>a rip - off twice {mask} , {mask} after [ seagal 's ] earlier copycat under siege , sometimes referred to as die hard on a boat .</td>\n",
       "      <td>a rip - off twice {neg_verb} , {neg_verb} after [ seagal 's ] earlier copycat under siege , sometimes referred to as die hard on a boat .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>what might have been readily dismissed as the tiresome rant of an aging filmmaker still thumbing his nose at convention takes a surprising , subtle turn at the midway point .</td>\n",
       "      <td>what might have been readily {mask} as the {mask} rant of an aging filmmaker still thumbing his nose at convention takes a surprising , subtle turn at the midway point .</td>\n",
       "      <td>what might have been readily {neg_verb} as the {neg_adj} rant of an aging filmmaker still thumbing his nose at convention takes a surprising , subtle turn at the midway point .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>the dialogue is cumbersome , the simpering soundtrack and editing more so .</td>\n",
       "      <td>the dialogue is {mask} , the {mask} soundtrack and editing more so .</td>\n",
       "      <td>the dialogue is {neg_adj} , the {neg_verb} soundtrack and editing more so .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>less cinematically powerful than quietly and deeply moving , which is powerful in itself .</td>\n",
       "      <td>less cinematically {mask} than quietly and deeply moving , which is {mask} in itself .</td>\n",
       "      <td>less cinematically {pos_adj} than quietly and deeply moving , which is {pos_adj} in itself .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>pratfalls aside , barbershop gets its greatest play from the timeless spectacle of people really talking to each other .</td>\n",
       "      <td>pratfalls aside , barbershop gets its greatest play from the {mask} spectacle of people really {mask} to each other .</td>\n",
       "      <td>pratfalls aside , barbershop gets its greatest play from the {pos_adj} spectacle of people really {pos_verb} to each other .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>an engrossing story that combines psychological drama , sociological reflection , and high-octane thriller .</td>\n",
       "      <td>an {mask} story that {mask} psychological drama , sociological reflection , and high - octane thriller .</td>\n",
       "      <td>an {pos_adj} story that {pos_verb} psychological drama , sociological reflection , and high - octane thriller .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>in imax in short , it's just as wonderful on the big screen .</td>\n",
       "      <td>in imax in {mask} , it 's just as {mask} on the big screen .</td>\n",
       "      <td>in imax in {neg_adj} , it 's just as {pos_adj} on the big screen .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>the rules of attraction gets us too drunk on the party favors to sober us up with the transparent attempts at moralizing .</td>\n",
       "      <td>the rules of attraction {mask} us too {mask} on the party favors to sober us up with the transparent attempts at moralizing .</td>\n",
       "      <td>the rules of attraction {pos_verb} us too {neg_adj} on the party favors to sober us up with the transparent attempts at moralizing .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>manages to accomplish what few sequels can -- it equals the original and in some ways even betters it .</td>\n",
       "      <td>{mask} to accomplish what few sequels can -- it equals the {mask} and in some ways even betters it .</td>\n",
       "      <td>{pos_verb} to accomplish what few sequels can -- it equals the {neg_adj} and in some ways even betters it .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>\" one look at a girl in tight pants and big tits and you turn stupid ? \" um . . isn't that the basis for the entire plot ?</td>\n",
       "      <td>\" one look at a girl in tight pants and big tits and you turn {mask} ? \" um   . . is n't that the basis for the {mask} plot ?</td>\n",
       "      <td>\" one look at a girl in tight pants and big tits and you turn {neg_adj} ? \" um   . . is n't that the basis for the {neg_adj} plot ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>charly comes off as emotionally manipulative and sadly imitative of innumerable past love story derisions .</td>\n",
       "      <td>charly comes off as emotionally {mask} and sadly {mask} of innumerable past love story derisions .</td>\n",
       "      <td>charly comes off as emotionally {neg_adj} and sadly {pos_adj} of innumerable past love story derisions .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>tully is worth a look for its true-to-life characters , its sensitive acting , its unadorned view of rural life and the subtle direction of first-timer hilary birmingham .</td>\n",
       "      <td>tully is {mask} a look for its true - to - life characters , its {mask} acting , its unadorned view of rural life and the subtle direction of first - timer hilary birmingham .</td>\n",
       "      <td>tully is {pos_adj} a look for its true - to - life characters , its {neg_adj} acting , its unadorned view of rural life and the subtle direction of first - timer hilary birmingham .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>the high-concept scenario soon proves preposterous , the acting is robotically italicized , and truth-in-advertising hounds take note : there's very little hustling on view .</td>\n",
       "      <td>the high - concept scenario soon proves {mask} , the acting is robotically {mask} , and truth - in - advertising hounds take note : there 's very little hustling on view .</td>\n",
       "      <td>the high - concept scenario soon proves {neg_adj} , the acting is robotically {neg_verb} , and truth - in - advertising hounds take note : there 's very little hustling on view .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>[lee] treats his audience the same way that jim brown treats his women -- as dumb , credulous , unassuming , subordinate subjects . and lee seems just as expectant of an adoring , wide-smiling reception .</td>\n",
       "      <td>[ lee ] treats his audience the same way that jim brown treats his women -- as {mask} , credulous , unassuming , subordinate subjects . and lee seems just as {mask} of an adoring , wide - smiling reception .</td>\n",
       "      <td>[ lee ] treats his audience the same way that jim brown treats his women -- as {neg_adj} , credulous , unassuming , subordinate subjects . and lee seems just as {neg_adj} of an adoring , wide - smiling reception .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>a wannabe comedy of manners about a brainy prep-school kid with a mrs . robinson complex founders on its own preciousness -- and squanders its beautiful women .</td>\n",
       "      <td>a {mask} comedy of manners about a brainy prep - school kid with a mrs . robinson complex founders on its own preciousness -- and {mask} its beautiful women .</td>\n",
       "      <td>a {neg_adj} comedy of manners about a brainy prep - school kid with a mrs . robinson complex founders on its own preciousness -- and {neg_verb} its beautiful women .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>seeing as the film lacks momentum and its position remains mostly undeterminable , the director's experiment is a successful one .</td>\n",
       "      <td>seeing as the film lacks momentum and its position remains mostly {mask} , the director 's experiment is a {mask} one .</td>\n",
       "      <td>seeing as the film lacks momentum and its position remains mostly {neg_adj} , the director 's experiment is a {pos_adj} one .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>a brilliant , absurd collection of vignettes that , in their own idiosyncratic way , sum up the strange horror of life in the new millennium .</td>\n",
       "      <td>a {mask} , absurd collection of vignettes that , in their own idiosyncratic way , {mask} up the strange horror of life in the new millennium .</td>\n",
       "      <td>a {pos_adj} , absurd collection of vignettes that , in their own idiosyncratic way , {neg_verb} up the strange horror of life in the new millennium .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>a pointed , often tender , examination of the pros and cons of unconditional love and familial duties .</td>\n",
       "      <td>a pointed , often {mask} , examination of the pros and cons of {mask} love and familial duties .</td>\n",
       "      <td>a pointed , often {pos_adj} , examination of the pros and cons of {pos_adj} love and familial duties .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>leaves viewers out in the cold and undermines some phenomenal performances .</td>\n",
       "      <td>leaves viewers out in the cold and {mask} some {mask} performances .</td>\n",
       "      <td>leaves viewers out in the cold and {neg_verb} some {pos_adj} performances .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>a much more successful translation than its most famous previous film adaptation , writer-director anthony friedman's similarly updated 1970 british production .</td>\n",
       "      <td>a much more {mask} translation than its most famous {mask} film adaptation , writer - director anthony friedman 's similarly updated 1970 british production .</td>\n",
       "      <td>a much more {pos_adj} translation than its most famous {neg_adj} film adaptation , writer - director anthony friedman 's similarly updated 1970 british production .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>this chicago has hugely imaginative and successful casting to its great credit , as well as one terrific score and attitude to spare .</td>\n",
       "      <td>this chicago has hugely imaginative and successful casting to its great credit , as well as one {mask} score and attitude to {mask} .</td>\n",
       "      <td>this chicago has hugely imaginative and successful casting to its great credit , as well as one {pos_adj} score and attitude to {neg_verb} .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  \\\n",
       "0       1   \n",
       "1       1   \n",
       "2       0   \n",
       "3       1   \n",
       "4       1   \n",
       "5       0   \n",
       "6       1   \n",
       "7       0   \n",
       "8       1   \n",
       "9       1   \n",
       "10      1   \n",
       "11      1   \n",
       "12      0   \n",
       "13      1   \n",
       "14      0   \n",
       "15      0   \n",
       "16      1   \n",
       "17      0   \n",
       "18      0   \n",
       "19      0   \n",
       "20      1   \n",
       "21      1   \n",
       "22      1   \n",
       "23      0   \n",
       "24      1   \n",
       "25      1   \n",
       "\n",
       "                                                                                                                                                                                                   original_text  \\\n",
       "0                                                                                                                                                                   unpretentious , charming , quirky , original   \n",
       "1                                           working from a surprisingly sensitive script co-written by gianni romoli . . . ozpetek avoids most of the pitfalls you'd expect in such a potentially sudsy set-up .   \n",
       "2                                                                         it's like a \" big chill \" reunion of the baader-meinhof gang , only these guys are more harmless pranksters than political activists .   \n",
       "3                                                                                                                             the stunt work is top-notch ; the dialogue and drama often food-spittingly funny .   \n",
       "4                                                                                                                                           an original and highly cerebral examination of the psychopathic mind   \n",
       "5                                                                                 a rip-off twice removed , modeled after [seagal's] earlier copycat under siege , sometimes referred to as die hard on a boat .   \n",
       "6                                 what might have been readily dismissed as the tiresome rant of an aging filmmaker still thumbing his nose at convention takes a surprising , subtle turn at the midway point .   \n",
       "7                                                                                                                                    the dialogue is cumbersome , the simpering soundtrack and editing more so .   \n",
       "8                                                                                                                     less cinematically powerful than quietly and deeply moving , which is powerful in itself .   \n",
       "9                                                                                       pratfalls aside , barbershop gets its greatest play from the timeless spectacle of people really talking to each other .   \n",
       "10                                                                                                  an engrossing story that combines psychological drama , sociological reflection , and high-octane thriller .   \n",
       "11                                                                                                                                                 in imax in short , it's just as wonderful on the big screen .   \n",
       "12                                                                                    the rules of attraction gets us too drunk on the party favors to sober us up with the transparent attempts at moralizing .   \n",
       "13                                                                                                       manages to accomplish what few sequels can -- it equals the original and in some ways even betters it .   \n",
       "14                                                                                   \" one look at a girl in tight pants and big tits and you turn stupid ? \" um\n",
       " . . isn't that the basis for the entire plot ?   \n",
       "15                                                                                                   charly comes off as emotionally manipulative and sadly imitative of innumerable past love story derisions .   \n",
       "16                                   tully is worth a look for its true-to-life characters , its sensitive acting , its unadorned view of rural life and the subtle direction of first-timer hilary birmingham .   \n",
       "17                                the high-concept scenario soon proves preposterous , the acting is robotically italicized , and truth-in-advertising hounds take note : there's very little hustling on view .   \n",
       "18  [lee] treats his audience the same way that jim brown treats his women -- as dumb , credulous , unassuming , subordinate subjects . and lee seems just as expectant of an adoring , wide-smiling reception .   \n",
       "19                                              a wannabe comedy of manners about a brainy prep-school kid with a mrs . robinson complex founders on its own preciousness -- and squanders its beautiful women .   \n",
       "20                                                                            seeing as the film lacks momentum and its position remains mostly undeterminable , the director's experiment is a successful one .   \n",
       "21                                                                a brilliant , absurd collection of vignettes that , in their own idiosyncratic way , sum up the strange horror of life in the new millennium .   \n",
       "22                                                                                                       a pointed , often tender , examination of the pros and cons of unconditional love and familial duties .   \n",
       "23                                                                                                                                  leaves viewers out in the cold and undermines some phenomenal performances .   \n",
       "24                                             a much more successful translation than its most famous previous film adaptation , writer-director anthony friedman's similarly updated 1970 british production .   \n",
       "25                                                                        this chicago has hugely imaginative and successful casting to its great credit , as well as one terrific score and attitude to spare .   \n",
       "\n",
       "                                                                                                                                                                                                        masked_text  \\\n",
       "0                                                                                                                                                                               {mask} , charming , quirky , {mask}   \n",
       "1                                            working from a surprisingly {mask} script co - written by gianni romoli . . . ozpetek {mask} most of the pitfalls you 'd expect in such a potentially sudsy set - up .   \n",
       "2                                                                        it 's like a \" {mask} chill \" reunion of the baader - meinhof gang , only these guys are more {mask} pranksters than political activists .   \n",
       "3                                                                                                                          the stunt work is top - {mask} ; the dialogue and drama often food - spittingly {mask} .   \n",
       "4                                                                                                                                                      an {mask} and highly cerebral examination of the {mask} mind   \n",
       "5                                                                                 a rip - off twice {mask} , {mask} after [ seagal 's ] earlier copycat under siege , sometimes referred to as die hard on a boat .   \n",
       "6                                         what might have been readily {mask} as the {mask} rant of an aging filmmaker still thumbing his nose at convention takes a surprising , subtle turn at the midway point .   \n",
       "7                                                                                                                                              the dialogue is {mask} , the {mask} soundtrack and editing more so .   \n",
       "8                                                                                                                            less cinematically {mask} than quietly and deeply moving , which is {mask} in itself .   \n",
       "9                                                                                             pratfalls aside , barbershop gets its greatest play from the {mask} spectacle of people really {mask} to each other .   \n",
       "10                                                                                                         an {mask} story that {mask} psychological drama , sociological reflection , and high - octane thriller .   \n",
       "11                                                                                                                                                     in imax in {mask} , it 's just as {mask} on the big screen .   \n",
       "12                                                                                    the rules of attraction {mask} us too {mask} on the party favors to sober us up with the transparent attempts at moralizing .   \n",
       "13                                                                                                             {mask} to accomplish what few sequels can -- it equals the {mask} and in some ways even betters it .   \n",
       "14                                                                                   \" one look at a girl in tight pants and big tits and you turn {mask} ? \" um \n",
       "  . . is n't that the basis for the {mask} plot ?   \n",
       "15                                                                                                               charly comes off as emotionally {mask} and sadly {mask} of innumerable past love story derisions .   \n",
       "16                                  tully is {mask} a look for its true - to - life characters , its {mask} acting , its unadorned view of rural life and the subtle direction of first - timer hilary birmingham .   \n",
       "17                                      the high - concept scenario soon proves {mask} , the acting is robotically {mask} , and truth - in - advertising hounds take note : there 's very little hustling on view .   \n",
       "18  [ lee ] treats his audience the same way that jim brown treats his women -- as {mask} , credulous , unassuming , subordinate subjects . and lee seems just as {mask} of an adoring , wide - smiling reception .   \n",
       "19                                                   a {mask} comedy of manners about a brainy prep - school kid with a mrs . robinson complex founders on its own preciousness -- and {mask} its beautiful women .   \n",
       "20                                                                                          seeing as the film lacks momentum and its position remains mostly {mask} , the director 's experiment is a {mask} one .   \n",
       "21                                                                   a {mask} , absurd collection of vignettes that , in their own idiosyncratic way , {mask} up the strange horror of life in the new millennium .   \n",
       "22                                                                                                                 a pointed , often {mask} , examination of the pros and cons of {mask} love and familial duties .   \n",
       "23                                                                                                                                             leaves viewers out in the cold and {mask} some {mask} performances .   \n",
       "24                                                   a much more {mask} translation than its most famous {mask} film adaptation , writer - director anthony friedman 's similarly updated 1970 british production .   \n",
       "25                                                                            this chicago has hugely imaginative and successful casting to its great credit , as well as one {mask} score and attitude to {mask} .   \n",
       "\n",
       "                                                                                                                                                                                                            template_text  \n",
       "0                                                                                                                                                                               {neg_adj} , charming , quirky , {neg_adj}  \n",
       "1                                           working from a surprisingly {neg_adj} script co - written by gianni romoli . . . ozpetek {neg_verb} most of the pitfalls you 'd expect in such a potentially sudsy set - up .  \n",
       "2                                                                        it 's like a \" {neg_adj} chill \" reunion of the baader - meinhof gang , only these guys are more {neg_adj} pranksters than political activists .  \n",
       "3                                                                                                                          the stunt work is top - {pos_adj} ; the dialogue and drama often food - spittingly {pos_adj} .  \n",
       "4                                                                                                                                                      an {neg_adj} and highly cerebral examination of the {neg_adj} mind  \n",
       "5                                                                               a rip - off twice {neg_verb} , {neg_verb} after [ seagal 's ] earlier copycat under siege , sometimes referred to as die hard on a boat .  \n",
       "6                                        what might have been readily {neg_verb} as the {neg_adj} rant of an aging filmmaker still thumbing his nose at convention takes a surprising , subtle turn at the midway point .  \n",
       "7                                                                                                                                             the dialogue is {neg_adj} , the {neg_verb} soundtrack and editing more so .  \n",
       "8                                                                                                                            less cinematically {pos_adj} than quietly and deeply moving , which is {pos_adj} in itself .  \n",
       "9                                                                                            pratfalls aside , barbershop gets its greatest play from the {pos_adj} spectacle of people really {pos_verb} to each other .  \n",
       "10                                                                                                        an {pos_adj} story that {pos_verb} psychological drama , sociological reflection , and high - octane thriller .  \n",
       "11                                                                                                                                                     in imax in {neg_adj} , it 's just as {pos_adj} on the big screen .  \n",
       "12                                                                                   the rules of attraction {pos_verb} us too {neg_adj} on the party favors to sober us up with the transparent attempts at moralizing .  \n",
       "13                                                                                                            {pos_verb} to accomplish what few sequels can -- it equals the {neg_adj} and in some ways even betters it .  \n",
       "14                                                                                   \" one look at a girl in tight pants and big tits and you turn {neg_adj} ? \" um \n",
       "  . . is n't that the basis for the {neg_adj} plot ?  \n",
       "15                                                                                                               charly comes off as emotionally {neg_adj} and sadly {pos_adj} of innumerable past love story derisions .  \n",
       "16                                  tully is {pos_adj} a look for its true - to - life characters , its {neg_adj} acting , its unadorned view of rural life and the subtle direction of first - timer hilary birmingham .  \n",
       "17                                     the high - concept scenario soon proves {neg_adj} , the acting is robotically {neg_verb} , and truth - in - advertising hounds take note : there 's very little hustling on view .  \n",
       "18  [ lee ] treats his audience the same way that jim brown treats his women -- as {neg_adj} , credulous , unassuming , subordinate subjects . and lee seems just as {neg_adj} of an adoring , wide - smiling reception .  \n",
       "19                                                  a {neg_adj} comedy of manners about a brainy prep - school kid with a mrs . robinson complex founders on its own preciousness -- and {neg_verb} its beautiful women .  \n",
       "20                                                                                          seeing as the film lacks momentum and its position remains mostly {neg_adj} , the director 's experiment is a {pos_adj} one .  \n",
       "21                                                                  a {pos_adj} , absurd collection of vignettes that , in their own idiosyncratic way , {neg_verb} up the strange horror of life in the new millennium .  \n",
       "22                                                                                                                 a pointed , often {pos_adj} , examination of the pros and cons of {pos_adj} love and familial duties .  \n",
       "23                                                                                                                                            leaves viewers out in the cold and {neg_verb} some {pos_adj} performances .  \n",
       "24                                                   a much more {pos_adj} translation than its most famous {neg_adj} film adaptation , writer - director anthony friedman 's similarly updated 1970 british production .  \n",
       "25                                                                           this chicago has hugely imaginative and successful casting to its great credit , as well as one {pos_adj} score and attitude to {neg_verb} .  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b26cf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pos_verb': ['combines', 'gets', 'talking', 'manages'], 'neg_verb': ['removed', 'undermines', 'spare', 'dismissed', 'sum', 'simpering', 'squanders', 'modeled', 'avoids', 'italicized'], 'pos_adj': ['imitative', 'brilliant', 'unconditional', 'timeless', 'notch', 'engrossing', 'successful', 'tender', 'funny', 'phenomenal', 'worth', 'powerful', 'wonderful', 'terrific'], 'neg_adj': ['entire', 'big', 'previous', 'short', 'manipulative', 'expectant', 'preposterous', 'wannabe', 'unpretentious', 'cumbersome', 'tiresome', 'stupid', 'drunk', 'sensitive', 'dumb', 'original', 'psychopathic', 'undeterminable', 'harmless']}\n"
     ]
    }
   ],
   "source": [
    "print(tg.lexicons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b218563",
   "metadata": {},
   "source": [
    "# Usando os templates gerados pelo TemplateGenerator no CheckList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "535bea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.editor import Editor\n",
    "from checklist.test_suite import TestSuite\n",
    "from checklist.test_types import MFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "247a1227",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicons = tg.lexicons\n",
    "templates = tg.template_texts\n",
    "masked = tg.masked_texts\n",
    "labels = [sent.prediction.label for sent in tg.sentences]\n",
    "\n",
    "editor = Editor()\n",
    "editor.add_lexicon('pos_verb', lexicons['pos_verb'])\n",
    "editor.add_lexicon('neg_verb', lexicons['neg_verb'])\n",
    "editor.add_lexicon('pos_adj', lexicons['pos_adj'])\n",
    "editor.add_lexicon('neg_adj', lexicons['neg_adj'])\n",
    "\n",
    "suite = TestSuite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b233f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for template, label, i in zip(templates, labels, range(len(templates))):\n",
    "    t = editor.template(template, remove_duplicates=True, labels=int(label))\n",
    "\n",
    "    suite.add(MFT(\n",
    "        data=t.data,\n",
    "        labels=label,\n",
    "        capability=\"Vocabullary\", \n",
    "        name=f\"Test: MFT with vocabullary - template{i+1}\",\n",
    "        description=\"Checking if the model can handle vocabullary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63e25aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test: MFT with vocabullary - template1\n",
      "Predicting 19 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10625/4227237112.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = softmax(tensor_logits[0]).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test: MFT with vocabullary - template2\n",
      "Predicting 190 examples\n",
      "Running Test: MFT with vocabullary - template3\n",
      "Predicting 19 examples\n",
      "Running Test: MFT with vocabullary - template4\n",
      "Predicting 14 examples\n",
      "Running Test: MFT with vocabullary - template5\n",
      "Predicting 19 examples\n",
      "Running Test: MFT with vocabullary - template6\n",
      "Predicting 10 examples\n",
      "Running Test: MFT with vocabullary - template7\n",
      "Predicting 190 examples\n",
      "Running Test: MFT with vocabullary - template8\n",
      "Predicting 190 examples\n",
      "Running Test: MFT with vocabullary - template9\n",
      "Predicting 14 examples\n",
      "Running Test: MFT with vocabullary - template10\n",
      "Predicting 56 examples\n",
      "Running Test: MFT with vocabullary - template11\n",
      "Predicting 56 examples\n",
      "Running Test: MFT with vocabullary - template12\n",
      "Predicting 266 examples\n",
      "Running Test: MFT with vocabullary - template13\n",
      "Predicting 76 examples\n",
      "Running Test: MFT with vocabullary - template14\n",
      "Predicting 76 examples\n",
      "Running Test: MFT with vocabullary - template15\n",
      "Predicting 19 examples\n",
      "Running Test: MFT with vocabullary - template16\n",
      "Predicting 266 examples\n",
      "Running Test: MFT with vocabullary - template17\n",
      "Predicting 266 examples\n",
      "Running Test: MFT with vocabullary - template18\n",
      "Predicting 190 examples\n",
      "Running Test: MFT with vocabullary - template19\n",
      "Predicting 19 examples\n",
      "Running Test: MFT with vocabullary - template20\n",
      "Predicting 190 examples\n",
      "Running Test: MFT with vocabullary - template21\n",
      "Predicting 266 examples\n",
      "Running Test: MFT with vocabullary - template22\n",
      "Predicting 140 examples\n",
      "Running Test: MFT with vocabullary - template23\n",
      "Predicting 14 examples\n",
      "Running Test: MFT with vocabullary - template24\n",
      "Predicting 140 examples\n",
      "Running Test: MFT with vocabullary - template25\n",
      "Predicting 266 examples\n",
      "Running Test: MFT with vocabullary - template26\n",
      "Predicting 140 examples\n"
     ]
    }
   ],
   "source": [
    "suite.run(model.predict, overwrite=True)\n",
    "suite.save('./suites/posneg-approach5.suite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea634cbe",
   "metadata": {},
   "source": [
    "# Carregando suite de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "526171ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.test_suite import TestSuite\n",
    "suite = TestSuite.from_file('./suites/posneg-approach5.suite')\n",
    "\n",
    "# suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4783de13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed = 732 (23.53%)\n",
      "passed = 2379 (76.47%)\n",
      "total = 3111\n",
      "templates: 26\n"
     ]
    }
   ],
   "source": [
    "passed = 0\n",
    "failed = 0\n",
    "for test_name in suite.tests:\n",
    "    table = suite.visual_summary_by_test(test_name)\n",
    "    \n",
    "    failed += table.stats['nfailed']    \n",
    "    passed += table.stats['npassed']\n",
    "    assert table.stats['nfailed'] + table.stats['npassed'] == len(table.filtered_testcases)\n",
    "\n",
    "print(f\"{failed = } ({(failed/(passed+failed))*100:.2f}%)\")\n",
    "print(f\"{passed = } ({(passed/(passed+failed))*100:.2f}%)\")\n",
    "print(f\"total = {passed+failed}\")\n",
    "print(\"templates:\", len(suite.tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "pressed-cutting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 's like a \" sensitive chill \" reunion of the baader - meinhof gang , only these guys are more sensitive pranksters than political activists .\n"
     ]
    }
   ],
   "source": [
    "table = suite.visual_summary_by_test('Test: MFT with vocabullary - template3')\n",
    "\n",
    "for item in table.candidate_testcases:\n",
    "    print(item['examples'][0]['new']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dirty-voluntary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed=732\n",
      "passed=3111\n",
      "passed+failed=3843\n"
     ]
    }
   ],
   "source": [
    "passed = 0\n",
    "failed = 0\n",
    "for i in range(len(templates)):\n",
    "    table = suite.visual_summary_by_test(f'Test: MFT with vocabullary - template{i+1}')\n",
    "    failed = failed + len(table.candidate_testcases)    \n",
    "    passed = passed + len(table.filtered_testcases)\n",
    "\n",
    "print(f\"{failed=}\", f\"{passed=}\", f\"{passed+failed=}\", sep=\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "335f8eac43d2678591a8076d8dfd5de078961fe9395efec4dfbbe61965ca9377"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
