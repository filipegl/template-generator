{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0e2c728",
   "metadata": {},
   "source": [
    "# Abordagem 4\n",
    "\n",
    "Usando a abordagem 4 para gerar templates com foco em templates positivos e negativos. Uma possível aplicação seria testar a capacidade linguística *Vocabullary* com o teste **MFT**.\n",
    "\n",
    "As etapas desta abordagem são:\n",
    "\n",
    "1. Classificar as instancias usando o *Oráculo*\n",
    "2. Filtrar instâncias classificadas de forma unânime\n",
    "3. Quebrar a instância em sentenças\n",
    "4. Classificar as sentenças usando o *Oráculo*\n",
    "5. Filtrar as sentenças classificadas de forma unânime\n",
    "6. Filtrar as sentenças com alta confiança nas predições\n",
    "7. Rankear as palavras de cada sentença\n",
    "8. Filtrar sentenças com palavras relevantes (verbos ou adjetivos) bem rankeadas\n",
    "9. Filtrar sentenças com alta confiança na predição das palavras relevantes \n",
    "10. Substituir as palavras relevantes por máscaras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "897c3a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da847fc",
   "metadata": {},
   "source": [
    "## Carregando o dataset, o modelo alvo e os modelos auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6e018fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unpretentious , charming , quirky , original</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a film really has to be exceptional to justify a three hour running time , and this isn't .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>working from a surprisingly sensitive script co-written by gianni romoli . . . ozpetek avoids most of the pitfalls you'd expect in such a potentially sudsy set-up .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it may not be particularly innovative , but the film's crisp , unaffected style and air of gentle longing make it unexpectedly rewarding .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>such a premise is ripe for all manner of lunacy , but kaufman and gondry rarely seem sure of where it should go .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ice age is the first computer-generated feature cartoon to feel like other movies , and that makes for some glacial pacing early on .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>there's no denying that burns is a filmmaker with a bright future ahead of him .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>it collapses when mr . taylor tries to shift the tone to a thriller's rush .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>there's a great deal of corny dialogue and preposterous moments . and yet , it still works .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ah , the travails of metropolitan life ! alas , another breathless movie about same !</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                    text   \n",
       "0                                                                                                                           unpretentious , charming , quirky , original  \\\n",
       "1                                                                            a film really has to be exceptional to justify a three hour running time , and this isn't .   \n",
       "2   working from a surprisingly sensitive script co-written by gianni romoli . . . ozpetek avoids most of the pitfalls you'd expect in such a potentially sudsy set-up .   \n",
       "3                             it may not be particularly innovative , but the film's crisp , unaffected style and air of gentle longing make it unexpectedly rewarding .   \n",
       "4                                                      such a premise is ripe for all manner of lunacy , but kaufman and gondry rarely seem sure of where it should go .   \n",
       "..                                                                                                                                                                   ...   \n",
       "95                                 ice age is the first computer-generated feature cartoon to feel like other movies , and that makes for some glacial pacing early on .   \n",
       "96                                                                                      there's no denying that burns is a filmmaker with a bright future ahead of him .   \n",
       "97                                                                                          it collapses when mr . taylor tries to shift the tone to a thriller's rush .   \n",
       "98                                                                          there's a great deal of corny dialogue and preposterous moments . and yet , it still works .   \n",
       "99                                                                                 ah , the travails of metropolitan life ! alas , another breathless movie about same !   \n",
       "\n",
       "    label  \n",
       "0       1  \n",
       "1       0  \n",
       "2       1  \n",
       "3       1  \n",
       "4       0  \n",
       "..    ...  \n",
       "95      0  \n",
       "96      1  \n",
       "97      0  \n",
       "98      1  \n",
       "99      0  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "dataset.set_format(\"pandas\")\n",
    "df = dataset[\"test\"].shuffle(seed=42)[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "264d0dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from torch.nn.functional import softmax\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "def pre_proccess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[\"\\',!-.:-@0-9/]()', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Wrapper to adapt output format\n",
    "class SentimentAnalisysModelWrapper:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __predict(self, text_input):\n",
    "        text_preprocessed = pre_proccess(text_input)\n",
    "        tokenized = self.tokenizer(text_preprocessed, padding=True, truncation=True, max_length=512, \n",
    "                                    add_special_tokens = True, return_tensors=\"pt\")\n",
    "        \n",
    "        tensor_logits = self.model(**tokenized)\n",
    "        prob = softmax(tensor_logits[0]).detach().numpy()\n",
    "        pred = np.argmax(prob)\n",
    "        \n",
    "        return pred, prob\n",
    "    \n",
    "    def predict_label(self, text_inputs):\n",
    "        return self.predict(text_inputs)[0]\n",
    "        \n",
    "    def predict_proba(self, text_inputs):\n",
    "        return self.predict(text_inputs)[1]\n",
    "        \n",
    "    def predict(self, text_inputs):\n",
    "        if isinstance(text_inputs, str):\n",
    "            text_inputs = [text_inputs]\n",
    "        \n",
    "        preds = []\n",
    "        probs = []\n",
    "\n",
    "        for text_input in text_inputs:\n",
    "            pred, prob = self.__predict(text_input)\n",
    "            preds.append(pred)\n",
    "            probs.append(prob[0])\n",
    "\n",
    "        return np.array(preds), np.array(probs) # ([0, 1], [[0.99, 0.01], [0.03, 0.97]])\n",
    "\n",
    "# Auxiliar function to load and wrap a model from Hugging Face\n",
    "def load_model(model_name):\n",
    "    print(f'Loading model {model_name}...')\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    return SentimentAnalisysModelWrapper(model, tokenizer)\n",
    "\n",
    "# Hugging Face hosted model names \n",
    "rotten_tomatoes_models = {\n",
    "    'bert': 'textattack/bert-base-uncased-rotten-tomatoes', \n",
    "    'albert': 'textattack/albert-base-v2-rotten-tomatoes', \n",
    "    'distilbert': 'textattack/distilbert-base-uncased-rotten-tomatoes', \n",
    "    'roberta': 'textattack/roberta-base-rotten-tomatoes', \n",
    "    'xlnet': 'textattack/xlnet-base-cased-rotten-tomatoes', \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f271eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model textattack/albert-base-v2-rotten-tomatoes...\n",
      "Loading model textattack/distilbert-base-uncased-rotten-tomatoes...\n",
      "Loading model textattack/roberta-base-rotten-tomatoes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-rotten-tomatoes were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model textattack/xlnet-base-cased-rotten-tomatoes...\n",
      "Loading model textattack/bert-base-uncased-rotten-tomatoes...\n"
     ]
    }
   ],
   "source": [
    "m1 = load_model(rotten_tomatoes_models['albert'])\n",
    "m2 = load_model(rotten_tomatoes_models['distilbert'])\n",
    "m3 = load_model(rotten_tomatoes_models['roberta'])\n",
    "m4 = load_model(rotten_tomatoes_models['xlnet'])\n",
    "\n",
    "# Models to be used as oracle\n",
    "models = [m1, m2, m3, m4]\n",
    "# Target model\n",
    "model = load_model(rotten_tomatoes_models['bert'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caae89b5",
   "metadata": {},
   "source": [
    "# Gerando os templates\n",
    "O método de rankeamento das palavras usado no PosNegTemplateGenerator é o Replace-1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60dc1af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from template_generator.tasks.sentiment_analisys import PosNegTemplateGeneratorApp4\n",
    "\n",
    "tg = PosNegTemplateGeneratorApp4(model, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f595e69",
   "metadata": {},
   "source": [
    "### Número inicial de instâncias: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6261506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling instances\n",
    "np.random.seed(220)\n",
    "n_instances = 5\n",
    "df_sampled = df.sample(n_instances)\n",
    "\n",
    "instances = [x for x in df_sampled['text'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "660add17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting inputs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13200/549501190.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = softmax(tensor_logits[0]).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Instance predictions done.\n",
      "Filtering instances classified unanimously...\n",
      ":: 5 instances remaining.\n",
      "Converting texts to sentences...\n",
      ":: 6 sentences were generated.\n",
      "Predicting inputs...\n",
      ":: Sentence predictions done.\n",
      "Filtering instances classified unanimously...\n",
      ":: 5 sentences remaining.\n",
      "Filtering instances by classification score greater than 0.8\n",
      ":: 5 sentences remaining.\n",
      "Ranking words using Replace-1 Score...\n",
      ":: Word ranking done.\n",
      "Filtering instances by relevant words...\n",
      ":: 3 sentences remaining.\n",
      "Filtering instances by relevant words classification score greater than 0.8\n",
      ":: 2 sentences remaining.\n"
     ]
    }
   ],
   "source": [
    "templates = tg.generate_templates(instances, ranked_words_count=4, min_classification_score=0.8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ff5c8cb",
   "metadata": {},
   "source": [
    "#### Tempo de execução para 5 instâncias: 1m 23.9s\n",
    "filipe: 43.6s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "193f1b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>original_text</th>\n",
       "      <th>masked_text</th>\n",
       "      <th>template_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>the rules of attraction gets us too drunk on the party favors to sober us up with the transparent attempts at moralizing .</td>\n",
       "      <td>the rules of attraction {mask} us too {mask} on the party favors to sober us up with the transparent attempts at moralizing .</td>\n",
       "      <td>the rules of attraction {pos_verb} us too {neg_verb} on the party favors to sober us up with the transparent attempts at moralizing .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>the high-concept scenario soon proves preposterous , the acting is robotically italicized , and truth-in-advertising hounds take note : there's very little hustling on view .</td>\n",
       "      <td>the high-concept scenario soon proves {mask} , the acting is robotically {mask} , and truth-in-advertising hounds take note : there 's very little hustling on view .</td>\n",
       "      <td>the high-concept scenario soon proves {neg_adj} , the acting is robotically {neg_verb} , and truth-in-advertising hounds take note : there 's very little hustling on view .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label   \n",
       "0      0  \\\n",
       "1      0   \n",
       "\n",
       "                                                                                                                                                                    original_text   \n",
       "0                                                      the rules of attraction gets us too drunk on the party favors to sober us up with the transparent attempts at moralizing .  \\\n",
       "1  the high-concept scenario soon proves preposterous , the acting is robotically italicized , and truth-in-advertising hounds take note : there's very little hustling on view .   \n",
       "\n",
       "                                                                                                                                                             masked_text   \n",
       "0                                          the rules of attraction {mask} us too {mask} on the party favors to sober us up with the transparent attempts at moralizing .  \\\n",
       "1  the high-concept scenario soon proves {mask} , the acting is robotically {mask} , and truth-in-advertising hounds take note : there 's very little hustling on view .   \n",
       "\n",
       "                                                                                                                                                                  template_text  \n",
       "0                                         the rules of attraction {pos_verb} us too {neg_verb} on the party favors to sober us up with the transparent attempts at moralizing .  \n",
       "1  the high-concept scenario soon proves {neg_adj} , the acting is robotically {neg_verb} , and truth-in-advertising hounds take note : there 's very little hustling on view .  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg.to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c03851be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_verb': ['gets'],\n",
       " 'neg_verb': ['italicized', 'drunk'],\n",
       " 'pos_adj': [],\n",
       " 'neg_adj': ['preposterous']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg.lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a27f1f",
   "metadata": {},
   "source": [
    "### Número inicial de instâncias: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd4a7fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using all 100 instances\n",
    "instances = [x for x in df['text'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1f3f383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting inputs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13200/549501190.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = softmax(tensor_logits[0]).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Instance predictions done.\n",
      "Filtering instances classified unanimously...\n",
      ":: 74 instances remaining.\n",
      "Converting texts to sentences...\n",
      ":: 96 sentences were generated.\n",
      "Predicting inputs...\n",
      ":: Sentence predictions done.\n",
      "Filtering instances classified unanimously...\n",
      ":: 82 sentences remaining.\n",
      "Filtering instances by classification score greater than 0.8\n",
      ":: 75 sentences remaining.\n",
      "Ranking words using Replace-1 Score...\n",
      ":: Word ranking done.\n",
      "Filtering instances by relevant words...\n",
      ":: 34 sentences remaining.\n",
      "Filtering instances by relevant words classification score greater than 0.8\n",
      ":: 19 sentences remaining.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 1m 7.1s\n",
    "tg = PosNegTemplateGeneratorApp4(model, models)\n",
    "templates = tg.generate_templates(instances, ranked_words_count=4, min_classification_score=0.8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "677154d8",
   "metadata": {},
   "source": [
    "#### Tempo de execução para 100 instâncias: 1m 10.4s\n",
    "filipe: 1m 10.4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c3c1541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>original_text</th>\n",
       "      <th>masked_text</th>\n",
       "      <th>template_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>we started to wonder if  some unpaid intern had just typed 'chris rock , ' 'anthony hopkins' and 'terrorists' into some univac-like script machine .</td>\n",
       "      <td>we {mask} to {mask} if some unpaid intern had just typed 'chris rock , ' 'anthony hopkins ' and 'terrorists ' into some univac-like script machine .</td>\n",
       "      <td>we {neg_verb} to {neg_verb} if some unpaid intern had just typed 'chris rock , ' 'anthony hopkins ' and 'terrorists ' into some univac-like script machine .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>what ensues are much blood-splattering , mass drug-induced bowel evacuations , and none-too-funny commentary on the cultural distinctions between americans and brits .</td>\n",
       "      <td>what ensues {mask} much blood-splattering , mass drug-induced bowel evacuations , and {mask} commentary on the cultural distinctions between americans and brits .</td>\n",
       "      <td>what ensues {neg_verb} much blood-splattering , mass drug-induced bowel evacuations , and {neg_adj} commentary on the cultural distinctions between americans and brits .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>the stunt work is top-notch ; the dialogue and drama often food-spittingly funny .</td>\n",
       "      <td>the stunt work is {mask} ; the dialogue and drama often food-spittingly {mask} .</td>\n",
       "      <td>the stunt work is {pos_adj} ; the dialogue and drama often food-spittingly {pos_adj} .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>an original and highly cerebral examination of the psychopathic mind</td>\n",
       "      <td>an {mask} and highly cerebral examination of the {mask} mind</td>\n",
       "      <td>an {neg_adj} and highly cerebral examination of the {neg_adj} mind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>death to smoochy tells a moldy-oldie , not-nearly -as-nasty -as-it- thinks-it-is joke .</td>\n",
       "      <td>death to {mask} tells a moldy-oldie , not-nearly {mask} -as-it- thinks-it-is joke .</td>\n",
       "      <td>death to {neg_verb} tells a moldy-oldie , not-nearly {neg_adj} -as-it- thinks-it-is joke .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>a rip-off twice removed , modeled after [seagal's] earlier copycat under siege , sometimes referred to as die hard on a boat .</td>\n",
       "      <td>a rip-off twice {mask} , {mask} after [ seagal 's ] earlier copycat under siege , sometimes referred to as die hard on a boat .</td>\n",
       "      <td>a rip-off twice {neg_verb} , {neg_verb} after [ seagal 's ] earlier copycat under siege , sometimes referred to as die hard on a boat .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>too bad none of it is funny .</td>\n",
       "      <td>too {mask} none of it is {mask} .</td>\n",
       "      <td>too {neg_adj} none of it is {pos_adj} .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>the dialogue is cumbersome , the simpering soundtrack and editing more so .</td>\n",
       "      <td>the dialogue is cumbersome , the {mask} soundtrack and {mask} more so .</td>\n",
       "      <td>the dialogue is cumbersome , the {neg_verb} soundtrack and {pos_verb} more so .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>an engrossing story that combines psychological drama , sociological reflection , and high-octane thriller .</td>\n",
       "      <td>an {mask} story that {mask} psychological drama , sociological reflection , and high-octane thriller .</td>\n",
       "      <td>an {pos_verb} story that {pos_verb} psychological drama , sociological reflection , and high-octane thriller .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>in imax in short , it's just as wonderful on the big screen .</td>\n",
       "      <td>in imax in {mask} , it 's just as {mask} on the big screen .</td>\n",
       "      <td>in imax in {neg_adj} , it 's just as {pos_adj} on the big screen .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>the rules of attraction gets us too drunk on the party favors to sober us up with the transparent attempts at moralizing .</td>\n",
       "      <td>the rules of attraction {mask} us too {mask} on the party favors to sober us up with the transparent attempts at moralizing .</td>\n",
       "      <td>the rules of attraction {pos_verb} us too {neg_verb} on the party favors to sober us up with the transparent attempts at moralizing .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>'dragonfly' dwells on crossing-over mumbo jumbo , manipulative sentimentality , and sappy dialogue .</td>\n",
       "      <td>'dragonfly ' dwells on crossing-over {mask} jumbo , manipulative sentimentality , and {mask} dialogue .</td>\n",
       "      <td>'dragonfly ' dwells on crossing-over {neg_adj} jumbo , manipulative sentimentality , and {neg_adj} dialogue .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>manages to accomplish what few sequels can -- it equals the original and in some ways even betters it .</td>\n",
       "      <td>manages to accomplish what few sequels {mask} -- it equals the {mask} and in some ways even betters it .</td>\n",
       "      <td>manages to accomplish what few sequels {neg_verb} -- it equals the {neg_adj} and in some ways even betters it .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>charly comes off as emotionally manipulative and sadly imitative of innumerable past love story derisions .</td>\n",
       "      <td>charly comes off as emotionally {mask} and sadly {mask} of innumerable past love story derisions .</td>\n",
       "      <td>charly comes off as emotionally {neg_adj} and sadly {pos_adj} of innumerable past love story derisions .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>the high-concept scenario soon proves preposterous , the acting is robotically italicized , and truth-in-advertising hounds take note : there's very little hustling on view .</td>\n",
       "      <td>the high-concept scenario soon proves {mask} , the acting is robotically {mask} , and truth-in-advertising hounds take note : there 's very little hustling on view .</td>\n",
       "      <td>the high-concept scenario soon proves {neg_adj} , the acting is robotically {neg_verb} , and truth-in-advertising hounds take note : there 's very little hustling on view .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>i was hoping that it would be sleazy and fun , but it was neither .</td>\n",
       "      <td>i was {mask} that it would be sleazy and fun , but it {mask} neither .</td>\n",
       "      <td>i was {neg_verb} that it would be sleazy and fun , but it {neg_verb} neither .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>seeing as the film lacks momentum and its position remains mostly undeterminable , the director's experiment is a successful one .</td>\n",
       "      <td>seeing as the film lacks momentum and its position remains mostly undeterminable , the director 's experiment {mask} a {mask} one .</td>\n",
       "      <td>seeing as the film lacks momentum and its position remains mostly undeterminable , the director 's experiment {pos_verb} a {pos_adj} one .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>leaves viewers out in the cold and undermines some phenomenal performances .</td>\n",
       "      <td>leaves viewers out in the cold and {mask} some {mask} performances .</td>\n",
       "      <td>leaves viewers out in the cold and {neg_verb} some {pos_adj} performances .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>a much more successful translation than its most famous previous film adaptation , writer-director anthony friedman's similarly updated 1970 british production .</td>\n",
       "      <td>a much more {mask} translation than its most famous {mask} film adaptation , writer-director anthony friedman 's similarly updated 1970 british production .</td>\n",
       "      <td>a much more {pos_adj} translation than its most famous {neg_adj} film adaptation , writer-director anthony friedman 's similarly updated 1970 british production .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label   \n",
       "0       0  \\\n",
       "1       0   \n",
       "2       1   \n",
       "3       1   \n",
       "4       0   \n",
       "5       0   \n",
       "6       0   \n",
       "7       0   \n",
       "8       1   \n",
       "9       1   \n",
       "10      0   \n",
       "11      0   \n",
       "12      1   \n",
       "13      0   \n",
       "14      0   \n",
       "15      0   \n",
       "16      1   \n",
       "17      0   \n",
       "18      1   \n",
       "\n",
       "                                                                                                                                                                     original_text   \n",
       "0                            we started to wonder if \n",
       " some unpaid intern had just typed 'chris rock , ' 'anthony hopkins' and 'terrorists' into some univac-like script machine .  \\\n",
       "1          what ensues are much blood-splattering , mass drug-induced bowel evacuations , and none-too-funny commentary on the cultural distinctions between americans and brits .   \n",
       "2                                                                                               the stunt work is top-notch ; the dialogue and drama often food-spittingly funny .   \n",
       "3                                                                                                             an original and highly cerebral examination of the psychopathic mind   \n",
       "4                                                                                          death to smoochy tells a moldy-oldie , not-nearly -as-nasty -as-it- thinks-it-is joke .   \n",
       "5                                                   a rip-off twice removed , modeled after [seagal's] earlier copycat under siege , sometimes referred to as die hard on a boat .   \n",
       "6                                                                                                                                                    too bad none of it is funny .   \n",
       "7                                                                                                      the dialogue is cumbersome , the simpering soundtrack and editing more so .   \n",
       "8                                                                     an engrossing story that combines psychological drama , sociological reflection , and high-octane thriller .   \n",
       "9                                                                                                                    in imax in short , it's just as wonderful on the big screen .   \n",
       "10                                                      the rules of attraction gets us too drunk on the party favors to sober us up with the transparent attempts at moralizing .   \n",
       "11                                                                            'dragonfly' dwells on crossing-over mumbo jumbo , manipulative sentimentality , and sappy dialogue .   \n",
       "12                                                                         manages to accomplish what few sequels can -- it equals the original and in some ways even betters it .   \n",
       "13                                                                     charly comes off as emotionally manipulative and sadly imitative of innumerable past love story derisions .   \n",
       "14  the high-concept scenario soon proves preposterous , the acting is robotically italicized , and truth-in-advertising hounds take note : there's very little hustling on view .   \n",
       "15                                                                                                             i was hoping that it would be sleazy and fun , but it was neither .   \n",
       "16                                              seeing as the film lacks momentum and its position remains mostly undeterminable , the director's experiment is a successful one .   \n",
       "17                                                                                                    leaves viewers out in the cold and undermines some phenomenal performances .   \n",
       "18               a much more successful translation than its most famous previous film adaptation , writer-director anthony friedman's similarly updated 1970 british production .   \n",
       "\n",
       "                                                                                                                                                              masked_text   \n",
       "0                    we {mask} to {mask} if some unpaid intern had just typed 'chris rock , ' 'anthony hopkins ' and 'terrorists ' into some univac-like script machine .  \\\n",
       "1      what ensues {mask} much blood-splattering , mass drug-induced bowel evacuations , and {mask} commentary on the cultural distinctions between americans and brits .   \n",
       "2                                                                                        the stunt work is {mask} ; the dialogue and drama often food-spittingly {mask} .   \n",
       "3                                                                                                            an {mask} and highly cerebral examination of the {mask} mind   \n",
       "4                                                                                     death to {mask} tells a moldy-oldie , not-nearly {mask} -as-it- thinks-it-is joke .   \n",
       "5                                         a rip-off twice {mask} , {mask} after [ seagal 's ] earlier copycat under siege , sometimes referred to as die hard on a boat .   \n",
       "6                                                                                                                                       too {mask} none of it is {mask} .   \n",
       "7                                                                                                 the dialogue is cumbersome , the {mask} soundtrack and {mask} more so .   \n",
       "8                                                                  an {mask} story that {mask} psychological drama , sociological reflection , and high-octane thriller .   \n",
       "9                                                                                                            in imax in {mask} , it 's just as {mask} on the big screen .   \n",
       "10                                          the rules of attraction {mask} us too {mask} on the party favors to sober us up with the transparent attempts at moralizing .   \n",
       "11                                                                'dragonfly ' dwells on crossing-over {mask} jumbo , manipulative sentimentality , and {mask} dialogue .   \n",
       "12                                                               manages to accomplish what few sequels {mask} -- it equals the {mask} and in some ways even betters it .   \n",
       "13                                                                     charly comes off as emotionally {mask} and sadly {mask} of innumerable past love story derisions .   \n",
       "14  the high-concept scenario soon proves {mask} , the acting is robotically {mask} , and truth-in-advertising hounds take note : there 's very little hustling on view .   \n",
       "15                                                                                                 i was {mask} that it would be sleazy and fun , but it {mask} neither .   \n",
       "16                                    seeing as the film lacks momentum and its position remains mostly undeterminable , the director 's experiment {mask} a {mask} one .   \n",
       "17                                                                                                   leaves viewers out in the cold and {mask} some {mask} performances .   \n",
       "18           a much more {mask} translation than its most famous {mask} film adaptation , writer-director anthony friedman 's similarly updated 1970 british production .   \n",
       "\n",
       "                                                                                                                                                                   template_text  \n",
       "0                   we {neg_verb} to {neg_verb} if some unpaid intern had just typed 'chris rock , ' 'anthony hopkins ' and 'terrorists ' into some univac-like script machine .  \n",
       "1      what ensues {neg_verb} much blood-splattering , mass drug-induced bowel evacuations , and {neg_adj} commentary on the cultural distinctions between americans and brits .  \n",
       "2                                                                                         the stunt work is {pos_adj} ; the dialogue and drama often food-spittingly {pos_adj} .  \n",
       "3                                                                                                             an {neg_adj} and highly cerebral examination of the {neg_adj} mind  \n",
       "4                                                                                     death to {neg_verb} tells a moldy-oldie , not-nearly {neg_adj} -as-it- thinks-it-is joke .  \n",
       "5                                        a rip-off twice {neg_verb} , {neg_verb} after [ seagal 's ] earlier copycat under siege , sometimes referred to as die hard on a boat .  \n",
       "6                                                                                                                                        too {neg_adj} none of it is {pos_adj} .  \n",
       "7                                                                                                the dialogue is cumbersome , the {neg_verb} soundtrack and {pos_verb} more so .  \n",
       "8                                                                 an {pos_verb} story that {pos_verb} psychological drama , sociological reflection , and high-octane thriller .  \n",
       "9                                                                                                             in imax in {neg_adj} , it 's just as {pos_adj} on the big screen .  \n",
       "10                                         the rules of attraction {pos_verb} us too {neg_verb} on the party favors to sober us up with the transparent attempts at moralizing .  \n",
       "11                                                                 'dragonfly ' dwells on crossing-over {neg_adj} jumbo , manipulative sentimentality , and {neg_adj} dialogue .  \n",
       "12                                                               manages to accomplish what few sequels {neg_verb} -- it equals the {neg_adj} and in some ways even betters it .  \n",
       "13                                                                      charly comes off as emotionally {neg_adj} and sadly {pos_adj} of innumerable past love story derisions .  \n",
       "14  the high-concept scenario soon proves {neg_adj} , the acting is robotically {neg_verb} , and truth-in-advertising hounds take note : there 's very little hustling on view .  \n",
       "15                                                                                                i was {neg_verb} that it would be sleazy and fun , but it {neg_verb} neither .  \n",
       "16                                    seeing as the film lacks momentum and its position remains mostly undeterminable , the director 's experiment {pos_verb} a {pos_adj} one .  \n",
       "17                                                                                                   leaves viewers out in the cold and {neg_verb} some {pos_adj} performances .  \n",
       "18            a much more {pos_adj} translation than its most famous {neg_adj} film adaptation , writer-director anthony friedman 's similarly updated 1970 british production .  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b26cf4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_verb': ['combines', 'gets', 'editing', 'is', 'engrossing'],\n",
       " 'neg_verb': ['italicized',\n",
       "  'smoochy',\n",
       "  'drunk',\n",
       "  'wonder',\n",
       "  'removed',\n",
       "  'was',\n",
       "  'are',\n",
       "  'hoping',\n",
       "  'started',\n",
       "  'modeled',\n",
       "  'simpering',\n",
       "  'undermines',\n",
       "  'can'],\n",
       " 'pos_adj': ['funny',\n",
       "  'imitative',\n",
       "  'wonderful',\n",
       "  'phenomenal',\n",
       "  'top-notch',\n",
       "  'successful'],\n",
       " 'neg_adj': ['sappy',\n",
       "  'short',\n",
       "  'original',\n",
       "  '-as-nasty',\n",
       "  'psychopathic',\n",
       "  'mumbo',\n",
       "  'preposterous',\n",
       "  'none-too-funny',\n",
       "  'previous',\n",
       "  'manipulative',\n",
       "  'bad']}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg.lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807b24d5",
   "metadata": {},
   "source": [
    "# Usando os templates gerados pelo TemplateGenerator no CheckList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05229cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.editor import Editor\n",
    "from checklist.test_suite import TestSuite\n",
    "from checklist.test_types import MFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "872fa1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicons = tg.lexicons\n",
    "templates = tg.template_texts\n",
    "masked = tg.masked_texts\n",
    "labels = [sent.prediction.label for sent in tg.sentences]\n",
    "\n",
    "editor = Editor()\n",
    "editor.add_lexicon('pos_verb', lexicons['pos_verb'])\n",
    "editor.add_lexicon('neg_verb', lexicons['neg_verb'])\n",
    "editor.add_lexicon('pos_adj', lexicons['pos_adj'])\n",
    "editor.add_lexicon('neg_adj', lexicons['neg_adj'])\n",
    "\n",
    "suite = TestSuite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cbcd9d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for template, label, i in zip(templates, labels, range(len(templates))):\n",
    "    t = editor.template(template, remove_duplicates=True, labels=int(label))\n",
    "\n",
    "    suite.add(MFT(\n",
    "        data=t.data,\n",
    "        labels=label,\n",
    "        capability=\"Vocabullary\", \n",
    "        name=f\"Test: MFT with vocabullary - template{i+1}\",\n",
    "        description=\"Checking if the model can handle vocabullary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61c18a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test: MFT with vocabullary - template1\n",
      "Predicting 13 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13200/549501190.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = softmax(tensor_logits[0]).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test: MFT with vocabullary - template2\n",
      "Predicting 143 examples\n",
      "Running Test: MFT with vocabullary - template3\n",
      "Predicting 6 examples\n",
      "Running Test: MFT with vocabullary - template4\n",
      "Predicting 11 examples\n",
      "Running Test: MFT with vocabullary - template5\n",
      "Predicting 143 examples\n",
      "Running Test: MFT with vocabullary - template6\n",
      "Predicting 13 examples\n",
      "Running Test: MFT with vocabullary - template7\n",
      "Predicting 66 examples\n",
      "Running Test: MFT with vocabullary - template8\n",
      "Predicting 65 examples\n",
      "Running Test: MFT with vocabullary - template9\n",
      "Predicting 5 examples\n",
      "Running Test: MFT with vocabullary - template10\n",
      "Predicting 66 examples\n",
      "Running Test: MFT with vocabullary - template11\n",
      "Predicting 65 examples\n",
      "Running Test: MFT with vocabullary - template12\n",
      "Predicting 11 examples\n",
      "Running Test: MFT with vocabullary - template13\n",
      "Predicting 143 examples\n",
      "Running Test: MFT with vocabullary - template14\n",
      "Predicting 66 examples\n",
      "Running Test: MFT with vocabullary - template15\n",
      "Predicting 143 examples\n",
      "Running Test: MFT with vocabullary - template16\n",
      "Predicting 13 examples\n",
      "Running Test: MFT with vocabullary - template17\n",
      "Predicting 30 examples\n",
      "Running Test: MFT with vocabullary - template18\n",
      "Predicting 78 examples\n",
      "Running Test: MFT with vocabullary - template19\n",
      "Predicting 66 examples\n"
     ]
    }
   ],
   "source": [
    "suite.run(model.predict, overwrite=True)\n",
    "suite.save('./suites/posneg-approach4.suite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8633d7",
   "metadata": {},
   "source": [
    "# Carregando suite de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5956571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.test_suite import TestSuite\n",
    "suite = TestSuite.from_file('./suites/posneg-approach4.suite')\n",
    "\n",
    "# suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2963325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed = 126 (10.99%)\n",
      "passed = 1020 (89.01%)\n",
      "total = 1146\n",
      "templates: 19\n"
     ]
    }
   ],
   "source": [
    "passed = 0\n",
    "failed = 0\n",
    "for test_name in suite.tests:\n",
    "    table = suite.visual_summary_by_test(test_name)\n",
    "    \n",
    "    failed += table.stats['nfailed']    \n",
    "    passed += table.stats['npassed']\n",
    "    assert table.stats['nfailed'] + table.stats['npassed'] == len(table.filtered_testcases)\n",
    "\n",
    "print(f\"{failed = } ({(failed/(passed+failed))*100:.2f}%)\")\n",
    "print(f\"{passed = } ({(passed/(passed+failed))*100:.2f}%)\")\n",
    "print(f\"total = {passed+failed}\")\n",
    "print(\"templates:\", len(suite.tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4f98304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'new': {'text': 'the dialogue is cumbersome , the italicized soundtrack and combines more so .', 'pred': '0', 'conf': 0.98235106, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'italicized', 'soundtrack', 'and', 'combines', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the italicized soundtrack and gets more so .', 'pred': '0', 'conf': 0.9937615, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'italicized', 'soundtrack', 'and', 'gets', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the italicized soundtrack and editing more so .', 'pred': '0', 'conf': 0.999332, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'italicized', 'soundtrack', 'and', 'editing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the italicized soundtrack and is more so .', 'pred': '0', 'conf': 0.9950937, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'italicized', 'soundtrack', 'and', 'is', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the italicized soundtrack and engrossing more so .', 'pred': '1', 'conf': 0.99936646, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'italicized', 'soundtrack', 'and', 'engrossing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 0}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the smoochy soundtrack and combines more so .', 'pred': '0', 'conf': 0.9949398, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'smoochy', 'soundtrack', 'and', 'combines', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the smoochy soundtrack and gets more so .', 'pred': '0', 'conf': 0.99780446, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'smoochy', 'soundtrack', 'and', 'gets', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the smoochy soundtrack and editing more so .', 'pred': '0', 'conf': 0.9994836, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'smoochy', 'soundtrack', 'and', 'editing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the smoochy soundtrack and is more so .', 'pred': '0', 'conf': 0.9986089, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'smoochy', 'soundtrack', 'and', 'is', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the smoochy soundtrack and engrossing more so .', 'pred': '1', 'conf': 0.9994142, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'smoochy', 'soundtrack', 'and', 'engrossing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 0}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the drunk soundtrack and combines more so .', 'pred': '0', 'conf': 0.9926763, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'drunk', 'soundtrack', 'and', 'combines', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the drunk soundtrack and gets more so .', 'pred': '0', 'conf': 0.997267, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'drunk', 'soundtrack', 'and', 'gets', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the drunk soundtrack and editing more so .', 'pred': '0', 'conf': 0.9994215, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'drunk', 'soundtrack', 'and', 'editing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the drunk soundtrack and is more so .', 'pred': '0', 'conf': 0.9981762, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'drunk', 'soundtrack', 'and', 'is', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the drunk soundtrack and engrossing more so .', 'pred': '1', 'conf': 0.99945503, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'drunk', 'soundtrack', 'and', 'engrossing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 0}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the wonder soundtrack and combines more so .', 'pred': '0', 'conf': 0.9269118, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'wonder', 'soundtrack', 'and', 'combines', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the wonder soundtrack and gets more so .', 'pred': '0', 'conf': 0.9519813, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'wonder', 'soundtrack', 'and', 'gets', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the wonder soundtrack and editing more so .', 'pred': '0', 'conf': 0.9986964, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'wonder', 'soundtrack', 'and', 'editing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the wonder soundtrack and is more so .', 'pred': '0', 'conf': 0.98949, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'wonder', 'soundtrack', 'and', 'is', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the wonder soundtrack and engrossing more so .', 'pred': '1', 'conf': 0.9995957, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'wonder', 'soundtrack', 'and', 'engrossing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 0}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the removed soundtrack and combines more so .', 'pred': '0', 'conf': 0.9901267, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'removed', 'soundtrack', 'and', 'combines', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the removed soundtrack and gets more so .', 'pred': '0', 'conf': 0.99667704, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'removed', 'soundtrack', 'and', 'gets', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the removed soundtrack and editing more so .', 'pred': '0', 'conf': 0.9992143, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'removed', 'soundtrack', 'and', 'editing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the removed soundtrack and is more so .', 'pred': '0', 'conf': 0.99583024, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'removed', 'soundtrack', 'and', 'is', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the removed soundtrack and engrossing more so .', 'pred': '1', 'conf': 0.9986953, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'removed', 'soundtrack', 'and', 'engrossing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 0}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the was soundtrack and combines more so .', 'pred': '0', 'conf': 0.9807068, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'was', 'soundtrack', 'and', 'combines', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the was soundtrack and gets more so .', 'pred': '0', 'conf': 0.9914072, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'was', 'soundtrack', 'and', 'gets', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the was soundtrack and editing more so .', 'pred': '0', 'conf': 0.99890125, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'was', 'soundtrack', 'and', 'editing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the was soundtrack and is more so .', 'pred': '0', 'conf': 0.99169296, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'was', 'soundtrack', 'and', 'is', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the was soundtrack and engrossing more so .', 'pred': '1', 'conf': 0.99947006, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'was', 'soundtrack', 'and', 'engrossing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 0}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the are soundtrack and combines more so .', 'pred': '0', 'conf': 0.97852933, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'are', 'soundtrack', 'and', 'combines', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the are soundtrack and gets more so .', 'pred': '0', 'conf': 0.98922193, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'are', 'soundtrack', 'and', 'gets', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the are soundtrack and editing more so .', 'pred': '0', 'conf': 0.9986376, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'are', 'soundtrack', 'and', 'editing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the are soundtrack and is more so .', 'pred': '0', 'conf': 0.9955915, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'are', 'soundtrack', 'and', 'is', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the are soundtrack and engrossing more so .', 'pred': '1', 'conf': 0.9994506, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'are', 'soundtrack', 'and', 'engrossing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 0}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the hoping soundtrack and combines more so .', 'pred': '0', 'conf': 0.86744153, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'hoping', 'soundtrack', 'and', 'combines', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the hoping soundtrack and gets more so .', 'pred': '0', 'conf': 0.9413494, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'hoping', 'soundtrack', 'and', 'gets', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the hoping soundtrack and editing more so .', 'pred': '0', 'conf': 0.9983512, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'hoping', 'soundtrack', 'and', 'editing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the hoping soundtrack and is more so .', 'pred': '0', 'conf': 0.9688954, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'hoping', 'soundtrack', 'and', 'is', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the hoping soundtrack and engrossing more so .', 'pred': '1', 'conf': 0.99948704, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'hoping', 'soundtrack', 'and', 'engrossing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 0}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the started soundtrack and combines more so .', 'pred': '0', 'conf': 0.6779779, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'started', 'soundtrack', 'and', 'combines', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the started soundtrack and gets more so .', 'pred': '0', 'conf': 0.93003273, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'started', 'soundtrack', 'and', 'gets', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the started soundtrack and editing more so .', 'pred': '0', 'conf': 0.99842536, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'started', 'soundtrack', 'and', 'editing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the started soundtrack and is more so .', 'pred': '0', 'conf': 0.9614113, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'started', 'soundtrack', 'and', 'is', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the started soundtrack and engrossing more so .', 'pred': '1', 'conf': 0.99928564, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'started', 'soundtrack', 'and', 'engrossing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 0}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the modeled soundtrack and combines more so .', 'pred': '0', 'conf': 0.9742982, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'modeled', 'soundtrack', 'and', 'combines', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the modeled soundtrack and gets more so .', 'pred': '0', 'conf': 0.99182594, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'modeled', 'soundtrack', 'and', 'gets', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the modeled soundtrack and editing more so .', 'pred': '0', 'conf': 0.9991374, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'modeled', 'soundtrack', 'and', 'editing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the modeled soundtrack and is more so .', 'pred': '0', 'conf': 0.9956949, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'modeled', 'soundtrack', 'and', 'is', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the modeled soundtrack and engrossing more so .', 'pred': '1', 'conf': 0.99935895, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'modeled', 'soundtrack', 'and', 'engrossing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 0}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the simpering soundtrack and combines more so .', 'pred': '0', 'conf': 0.95834845, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'simpering', 'soundtrack', 'and', 'combines', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the simpering soundtrack and gets more so .', 'pred': '0', 'conf': 0.9923942, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'simpering', 'soundtrack', 'and', 'gets', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the simpering soundtrack and editing more so .', 'pred': '0', 'conf': 0.99954, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'simpering', 'soundtrack', 'and', 'editing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the simpering soundtrack and is more so .', 'pred': '0', 'conf': 0.99567455, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'simpering', 'soundtrack', 'and', 'is', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the simpering soundtrack and engrossing more so .', 'pred': '1', 'conf': 0.99944645, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'simpering', 'soundtrack', 'and', 'engrossing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 0}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the undermines soundtrack and combines more so .', 'pred': '0', 'conf': 0.9915386, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'undermines', 'soundtrack', 'and', 'combines', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the undermines soundtrack and gets more so .', 'pred': '0', 'conf': 0.9964329, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'undermines', 'soundtrack', 'and', 'gets', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the undermines soundtrack and editing more so .', 'pred': '0', 'conf': 0.99945587, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'undermines', 'soundtrack', 'and', 'editing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the undermines soundtrack and is more so .', 'pred': '0', 'conf': 0.9974533, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'undermines', 'soundtrack', 'and', 'is', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the undermines soundtrack and engrossing more so .', 'pred': '1', 'conf': 0.99953425, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'undermines', 'soundtrack', 'and', 'engrossing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 0}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the can soundtrack and combines more so .', 'pred': '0', 'conf': 0.98803, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'can', 'soundtrack', 'and', 'combines', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the can soundtrack and gets more so .', 'pred': '0', 'conf': 0.9976053, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'can', 'soundtrack', 'and', 'gets', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the can soundtrack and editing more so .', 'pred': '0', 'conf': 0.99917775, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'can', 'soundtrack', 'and', 'editing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the can soundtrack and is more so .', 'pred': '0', 'conf': 0.99800724, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'can', 'soundtrack', 'and', 'is', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 1}\n",
      "{'new': {'text': 'the dialogue is cumbersome , the can soundtrack and engrossing more so .', 'pred': '1', 'conf': 0.99955755, 'tokens': [['the', 'dialogue', 'is', 'cumbersome', ',', 'the', 'can', 'soundtrack', 'and', 'engrossing', 'more', 'so', '.']]}, 'old': None, 'label': 0, 'succeed': 0}\n"
     ]
    }
   ],
   "source": [
    "table = suite.visual_summary_by_test('Test: MFT with vocabullary - template8')\n",
    "\n",
    "failed = table.candidate_testcases\n",
    "tests = table.filtered_testcases\n",
    "\n",
    "for item in tests:\n",
    "    # if not item in failed:\n",
    "    print(item['examples'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5290abd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed=271\n",
      "passed=1942\n",
      "passed+failed=2213\n"
     ]
    }
   ],
   "source": [
    "passed = 0\n",
    "failed = 0\n",
    "for i in range(len(suite.tests)):\n",
    "    table = suite.visual_summary_by_test(f'Test: MFT with vocabullary - template{i+1}')\n",
    "    failed = failed + len(table.candidate_testcases)    \n",
    "    passed = passed + len(table.filtered_testcases)\n",
    "\n",
    "print(f\"{failed=}\", f\"{passed=}\", f\"{passed+failed=}\", sep=\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "335f8eac43d2678591a8076d8dfd5de078961fe9395efec4dfbbe61965ca9377"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
