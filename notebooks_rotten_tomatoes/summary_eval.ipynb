{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rotten tomatoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['approach2.xlsx',\n",
       " 'approach1.xlsx',\n",
       " 'random.xlsx',\n",
       " 'approach4.xlsx',\n",
       " 'approach3.xlsx',\n",
       " 'approach5.xlsx']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DIR_NAME = \"./test_cases_rotten_tomatoes_rotulated_NO\"\n",
    "# DIR_NAME = \"../notebooks_amazon/test_cases_amazon_rotulated/test_cases_amazon_rotulated_NO\"\n",
    "DIR_NAME = \"../notebooks/test_cases_imdb_rotulated/test_cases_imdb_rotulated_with_NO/\"\n",
    "\n",
    "rotulated_approachs = os.listdir(DIR_NAME)\n",
    "rotulated_approachs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_classification(row):\n",
    "    if len(row[\"classification\"]) == 1:\n",
    "        if row[\"succeed\"] == 1:\n",
    "            row[\"classification\"] += \"N\"\n",
    "        elif row[\"succeed\"] == 0:\n",
    "            row[\"classification\"] += \"P\"\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_row(_df, t_name):\n",
    "    length = len(_df)\n",
    "    passing = len(_df.query(\"succeed == 1\"))\n",
    "    failing = len(_df.query(\"succeed == 0\"))\n",
    "    fn = len(_df.query(\"classification == 'FN'\"))\n",
    "    fp = len(_df.query(\"classification == 'FP'\"))\n",
    "    vn = len(_df.query(\"classification == 'VN'\"))\n",
    "    vp = len(_df.query(\"classification == 'VP'\"))\n",
    "    fn_no = len(_df.query(\"classification == 'FN' and subclassification == 'NO'\"))\n",
    "    fn_le = len(_df.query(\"classification == 'FN' and subclassification == 'LE'\"))\n",
    "    fn_te = len(_df.query(\"classification == 'FN' and subclassification == 'TE'\"))\n",
    "    fp_no = len(_df.query(\"classification == 'FP' and subclassification == 'NO'\"))\n",
    "    fp_le = len(_df.query(\"classification == 'FP' and subclassification == 'LE'\"))\n",
    "    fp_te = len(_df.query(\"classification == 'FP' and subclassification == 'TE'\"))\n",
    "    return [t_name, length, passing, failing, fn, fp, vn, vp, fn_no, fn_le, fn_te, fp_no, fp_le, fp_te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = [\n",
    "    \"template_name\", \"amostras\", \"passando\", \"falhando\", \"FN\", \"FP\", \"VN\", \"VP\", \"FN_NO\", \"FN_LE\", \"FN_NO\", \"FP_NO\", \"FP_LE\", \"FP_TE\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(os.path.join(DIR_NAME, \"summary.xlsx\")) as writer:\n",
    "    apps_summary_rows = []\n",
    "    for app in sorted(rotulated_approachs):\n",
    "        templates = pd.read_excel(os.path.join(DIR_NAME, app), sheet_name=None)\n",
    "        app_summary_rows = []\n",
    "        for t in list(templates.keys()):\n",
    "            if t==\"templates\":\n",
    "                continue\n",
    "            templates[t].columns = [\"text\", \"label\", \"pred\", \"succeed\", \"classification\", \"subclassification\", \"obs\"]\n",
    "            templates[t] = templates[t].apply(fill_classification, axis=1)\n",
    "\n",
    "            app_summ_row = get_summary_row(templates[t], t_name=t)\n",
    "            app_summary_rows.append(app_summ_row)\n",
    "        app_summary_df = pd.DataFrame(data=app_summary_rows, columns=new_columns)\n",
    "        app_summary_df.to_excel(writer, sheet_name=app, index=False)\n",
    "\n",
    "        apps_summary_rows.append([app] + app_summary_df.drop(columns=\"template_name\").sum().to_list())\n",
    "\n",
    "    apps_columns = [\"approach\"] + new_columns[1:]\n",
    "    apps_summary_df = pd.DataFrame(data=apps_summary_rows, columns=apps_columns).sort_values(\"approach\")\n",
    "    apps_summary_df.to_excel(writer, sheet_name=\"general_summary\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "app=\"approach3.xlsx\"\n",
    "templates = pd.read_excel(os.path.join(DIR_NAME, app), sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>succeed</th>\n",
       "      <th>classification</th>\n",
       "      <th>sub-classification</th>\n",
       "      <th>OBS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>an bad and highly cerebral examination of the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FP</td>\n",
       "      <td>TE</td>\n",
       "      <td>No template 'an original and highly cerebral e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>an short and highly cerebral examination of th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FP</td>\n",
       "      <td>TE</td>\n",
       "      <td>No template 'an original and highly cerebral e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>an credulous and highly cerebral examination o...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>FN</td>\n",
       "      <td>TE</td>\n",
       "      <td>No template 'an original and highly cerebral e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an none-too-funny and highly cerebral examinat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>FN</td>\n",
       "      <td>TE</td>\n",
       "      <td>No template 'an original and highly cerebral e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  pred  succeed   \n",
       "0  an bad and highly cerebral examination of the ...      1     0        0  \\\n",
       "1  an short and highly cerebral examination of th...      1     0        0   \n",
       "2  an credulous and highly cerebral examination o...      1     1        1   \n",
       "3  an none-too-funny and highly cerebral examinat...      1     1        1   \n",
       "\n",
       "  classification sub-classification   \n",
       "0             FP                 TE  \\\n",
       "1             FP                 TE   \n",
       "2             FN                 TE   \n",
       "3             FN                 TE   \n",
       "\n",
       "                                                 OBS  \n",
       "0  No template 'an original and highly cerebral e...  \n",
       "1  No template 'an original and highly cerebral e...  \n",
       "2  No template 'an original and highly cerebral e...  \n",
       "3  No template 'an original and highly cerebral e...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = templates[\"template4\"].apply(fill_classification, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FP': 2, 'FN': 2}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"classification\"].value_counts().to_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "checklist-templates",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
